{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# add parent directory to the path\n",
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Script to pre-process AML transaction data to be used in training and inference.\"\"\"\n",
    "import os\n",
    "import argparse\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Set the logging level\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',  # Specify the log message format\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',  # Specify the date format\n",
    "    handlers=[\n",
    "        #logging.FileHandler('app.log'),  # Log messages to a file\n",
    "        logging.StreamHandler()  # Also output log messages to the console\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/mnt/data/ibm-transactions-for-anti-money-laundering-aml/HI-Large_Trans.csv')\n",
    "# print the histogram of Amount Recieved column\n",
    "print(df['Amount Received'].hist(bins=10000, color='blue', edgecolor='black'))\n",
    "# print min and max\n",
    "print(df['Amount Received'].min())\n",
    "print(df['Amount Received'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Account\n",
      "80C746490        [20703, 19200]\n",
      "81A27EB30      [160226, 264674]\n",
      "81F71BE10       [60269, 157344]\n",
      "82954CE40      [144465, 143318]\n",
      "83212BF10    [2125527, 1135003]\n",
      "83214F0E0    [2129483, 2133788]\n",
      "8347C8F30    [2142416, 2142968]\n",
      "83510AC20       [51969, 243938]\n",
      "83B7523F0     [2121060, 298409]\n",
      "83FFB8A70     [172737, 1166034]\n",
      "84ADF03D0       [164028, 38633]\n",
      "851912640      [246267, 238428]\n",
      "Name: From Bank, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Group by 'Account' and aggregate 'From Bank'\n",
    "grouped = df.groupby('Account')['From Bank'].unique()\n",
    "\n",
    "# Find accounts with multiple banks\n",
    "duplicated_accounts = grouped[grouped.apply(lambda x: len(x) > 1)]\n",
    "\n",
    "print(duplicated_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 13:15:51 - INFO - Creating graph...\n",
      "2024-08-01 13:15:52 - INFO - Graph created in 0.87 seconds.\n",
      "2024-08-01 13:15:52 - INFO - Adding ports...\n",
      "2024-08-01 13:16:14 - INFO - Ports added in 22.65 seconds.\n",
      "2024-08-01 13:16:14 - INFO - Applying mask...\n",
      "2024-08-01 13:16:14 - INFO - Loading masked columns from /mnt/data/ibm-transactions-for-anti-money-laundering-aml/dummy-c.csv.npy\n",
      "2024-08-01 13:16:21 - INFO - Mask applied in 6.70 seconds.\n",
      "2024-08-01 13:16:22 - INFO - Materialzing dataset...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amount Received', 'Receiving Currency', 'Payment Format']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 13:16:33 - INFO - Materialized in 11.13 seconds\n",
      "2024-08-01 13:16:33 - INFO - Number of numerical columns: 1\n",
      "2024-08-01 13:16:33 - INFO - Number of categorical columns: 2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from src.datasets.util.mask import PretrainType\n",
    "from src.datasets import IBMTransactionsAML\n",
    "dataset = IBMTransactionsAML(\n",
    "    root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/dummy-c.csv', \n",
    "    pretrain={PretrainType.MASK, PretrainType.LINK_PRED},\n",
    "    split_type='daily_temporal',\n",
    "    splits=[0.6,0.2,0.2], \n",
    "    khop_neighbors=[100,100],\n",
    "    ports=True\n",
    ")\n",
    "logger.info(f\"Materialzing dataset...\")\n",
    "s = time.time()\n",
    "dataset.materialize()\n",
    "logger.info(f\"Materialized in {time.time() - s:.2f} seconds\")\n",
    "dataset.df.head(5)\n",
    "num_columns = len(dataset.num_columns)\n",
    "cat_columns = len(dataset.cat_columns)\n",
    "logger.info(f\"Number of numerical columns: {num_columns}\")\n",
    "logger.info(f\"Number of categorical columns: {cat_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 13:10:32 - INFO - train_loader size: 293\n",
      "2024-08-01 13:10:32 - INFO - val_loader size: 98\n",
      "2024-08-01 13:10:32 - INFO - test_loader size: 98\n"
     ]
    }
   ],
   "source": [
    "from torch_frame.data import DataLoader\n",
    "train_dataset, val_dataset, test_dataset = dataset.split()\n",
    "train_loader = DataLoader(train_dataset.tensor_frame, batch_size=1024, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset.tensor_frame, batch_size=1024, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset.tensor_frame, batch_size=1024, shuffle=False)\n",
    "logger.info(f\"train_loader size: {len(train_loader)}\")\n",
    "logger.info(f\"val_loader size: {len(val_loader)}\")\n",
    "logger.info(f\"test_loader size: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-01 13:10:34 - INFO - item: tensor([[0.0000e+00, 1.0000e+00, 2.5602e+05, 4.5660e+03, 4.1174e+05],\n",
      "        [2.0000e+00, 2.0000e+00, 1.5940e+05, 1.6216e+05, 4.2245e+05],\n",
      "        [0.0000e+00, 2.0000e+00, 2.3275e+05, 2.3275e+05, 3.1179e+05],\n",
      "        ...,\n",
      "        [7.0000e+00, 1.0000e+00, 1.6315e+05, 1.6314e+05, 2.1846e+05],\n",
      "        [3.6196e-01, 0.0000e+00, 1.7007e+05, 1.7007e+05, 2.2775e+05],\n",
      "        [2.0000e+00, 2.0000e+00, 2.1114e+05, 2.1044e+05, 2.8283e+05]],\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "item = next(iter(train_loader))\n",
    "logger.info(f\"item: {item.y}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rel-mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
