{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"The data stored in pickle format with version: 0.7.5 (python 3.7).\n",
    "The type of graph object：networkx.classes.multidigraph.MultiDiGraph\n",
    "Numbers of nodes: 2973489\n",
    "Numbers of edges: 13551303\n",
    "Average degree:   4.5574\n",
    "Nodes' features：\n",
    "    // The label. 1 means fishing mark node, otherwise 0.\n",
    "    G.nodes[nodeName]['isp']；\n",
    "\n",
    "Edges' features:\n",
    "    G[node1][node2][0]['amount']        // The amount mount of the transaction.\n",
    "    G[node1][node2][0]['timestamp']     // The timestamp of the transaction.\t\t\t\t\n",
    "\t\t\t\t\t\t\t\n",
    "* Notes * \n",
    "\"\"\"\n",
    "# Quick start tutorial.\n",
    "\n",
    "import pickle \n",
    "import networkx as nx\n",
    "\n",
    "def load_pickle(fname):\n",
    "    with open(fname, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "G = load_pickle('/mnt/data/ethereum-phishing-transaction-network/MulDiGraph.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0x1f1e784a61a8ca0a90250bcd2170696655b28a21\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Traversal nodes:\n",
    "for idx, nd in enumerate(nx.nodes(G)):\n",
    "    print(nd)\n",
    "    print(G.nodes[nd]['isp'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-08-07 07:01:09 2019-01-19 09:32:09\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "# Travelsal edges:\n",
    "min_time = 1e20\n",
    "max_time = 0\n",
    "for ind, edge in enumerate(nx.edges(G)):\n",
    "    (u, v) = edge\n",
    "    eg = G[u][v][0]\n",
    "    amo, tim = eg['amount'], eg['timestamp']\n",
    "    min_time = min(min_time, tim)\n",
    "    max_time = max(max_time, tim)\n",
    "min_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(min_time))\n",
    "max_time = time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(max_time))\n",
    "print(min_time, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                hash  nonce  \\\n",
      "0  0x5c504ed432cb51138bcf09aa5e8a410dd4a1e204ef84...      0   \n",
      "1  0x19f1df2c7ee6b464720ad28e903aeda1a5ad8780afc2...      0   \n",
      "2  0x9e6e19637bb625a8ff3d052b7c2fe57dc78c55a15d25...      0   \n",
      "3  0xcb9378977089c773c074045b20ede2cdcc3a6ff562f4...      0   \n",
      "4  0x570ce19176bd0002b04a9179309129bbdaf0c4252ffe...      0   \n",
      "\n",
      "                                          block_hash  block_number  \\\n",
      "0  0x4e3a3754410177e6937ef1f84bba68ea139e8d1a2258...         46147   \n",
      "1  0x5793f91c9fa8f824d8ed77fc1687dddcf334da81c68b...         46169   \n",
      "2  0xf4a537e8e2233149929a9b6964c9aced6ee95f42131a...         46170   \n",
      "3  0x47ec6a0c3467850cf88112c212c262819de6f1d084d3...         46194   \n",
      "4  0xe6fb31b12d06b5a70f420a28b4e034bcd152abc2d603...         46205   \n",
      "\n",
      "   transaction_index                                from_address  \\\n",
      "0                  0  0xa1e4380a3b1f749673e270229993ee55f35663b4   \n",
      "1                  0  0xbd08e0cddec097db7901ea819a3d1fd9de8951a2   \n",
      "2                  0  0x63ac545c991243fa18aec41d4f6f598e555015dc   \n",
      "3                  0  0x037dd056e7fdbd641db5b6bea2a8780a83fae180   \n",
      "4                  0  0x3f2f381491797cc5c0d48296c14fd0cd00cdfa2d   \n",
      "\n",
      "                                   to_address                  value    gas  \\\n",
      "0  0x5df9b87991262f6ba471f09758cde1c0fc1de734                  31337  21000   \n",
      "1  0x5c12a8e43faf884521c2454f39560e6c265a68c8   19900000000000000000  21000   \n",
      "2  0xc93f2250589a6563f5359051c1ea25746549f0d8  599989500000000000000  21000   \n",
      "3  0x7e7ec15a5944e978257ddae0008c2f2ece0a6090  100000000000000000000  21000   \n",
      "4  0x4bd5f0ee173c81d42765154865ee69361b6ad189  803989500000000000000  21000   \n",
      "\n",
      "        gas_price input  block_timestamp  max_fee_per_gas  \\\n",
      "0  50000000000000    0x       1438918233              NaN   \n",
      "1    909808707606    0x       1438918613              NaN   \n",
      "2    500000000000    0x       1438918630              NaN   \n",
      "3   1000000000000    0x       1438918983              NaN   \n",
      "4    500000000000    0x       1438919175              NaN   \n",
      "\n",
      "   max_priority_fee_per_gas  transaction_type  max_fee_per_blob_gas  \\\n",
      "0                       NaN                 0                   NaN   \n",
      "1                       NaN                 0                   NaN   \n",
      "2                       NaN                 0                   NaN   \n",
      "3                       NaN                 0                   NaN   \n",
      "4                       NaN                 0                   NaN   \n",
      "\n",
      "   blob_versioned_hashes  \n",
      "0                    NaN  \n",
      "1                    NaN  \n",
      "2                    NaN  \n",
      "3                    NaN  \n",
      "4                    NaN  \n",
      "7331505\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# get raw transactions\n",
    "transactions_path = '/mnt/data/ethereum-phishing-transaction-network/transactions.csv'\n",
    "df = pd.read_csv(transactions_path)\n",
    "print(df.head())\n",
    "print(df.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of matching edges: 119438\n",
      "Number of total edges: 13551303\n",
      "Percentage of matching edges: 0.008813764993668875\n"
     ]
    }
   ],
   "source": [
    "c = 0\n",
    "def count_matching_edges(edge_list, df):\n",
    "    # Convert the edge list to a set for faster lookup\n",
    "    edge_set = set(edge_list)\n",
    "    \n",
    "    # Create a boolean mask for matching edges\n",
    "    mask = df.apply(lambda row: (row['from_address'], row['to_address']) in edge_set, axis=1)\n",
    "    \n",
    "    \n",
    "    # Count the number of True values in the mask\n",
    "    count = mask.sum()\n",
    "    \n",
    "    return count\n",
    "\n",
    "edge_list = list(G.edges())\n",
    "matching_count = count_matching_edges(edge_list, df)\n",
    "print(f\"Number of matching edges: {matching_count}\")\n",
    "print(f\"Number of total edges: {len(edge_list)}\")\n",
    "print(f\"Percentage of matching edges: {matching_count/len(edge_list)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequest",
     "evalue": "400 Syntax error: Expected end of input but got identifier \"ASCLIMIT\" at [1:173]; reason: invalidQuery, location: query, message: Syntax error: Expected end of input but got identifier \"ASCLIMIT\" at [1:173]\n\nLocation: US\nJob ID: 32254874-aff3-4278-9ca6-7472a14915ef\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequest\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 20\u001b[0m\n\u001b[1;32m      7\u001b[0m QUERY \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# 'SELECT to_address, from_address FROM `bigquery-public-data.crypto_ethereum.transactions` '\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# f'WHERE to_address = {lol[0]}'\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# 'LIMIT 100'\u001b[39;00m\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m query_job \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery(QUERY)  \u001b[38;5;66;03m# API request\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[43mquery_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Waits for query to finish\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(row)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/gcloud/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py:1676\u001b[0m, in \u001b[0;36mQueryJob.result\u001b[0;34m(self, page_size, max_results, retry, timeout, start_index, job_retry)\u001b[0m\n\u001b[1;32m   1671\u001b[0m     remaining_timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1673\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1674\u001b[0m     \u001b[38;5;66;03m# Since is_job_done() calls jobs.getQueryResults, which is a\u001b[39;00m\n\u001b[1;32m   1675\u001b[0m     \u001b[38;5;66;03m# long-running API, don't delay the next request at all.\u001b[39;00m\n\u001b[0;32m-> 1676\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mis_job_done\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1677\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1679\u001b[0m     \u001b[38;5;66;03m# Use a monotonic clock since we don't actually care about\u001b[39;00m\n\u001b[1;32m   1680\u001b[0m     \u001b[38;5;66;03m# daylight savings or similar, just the elapsed time.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/gcloud/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/gcloud/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/gcloud/lib/python3.8/site-packages/google/api_core/retry/retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[1;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[1;32m    208\u001b[0m         error_list,\n\u001b[1;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[1;32m    210\u001b[0m         original_timeout,\n\u001b[1;32m    211\u001b[0m     )\n\u001b[0;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/gcloud/lib/python3.8/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/gcloud/lib/python3.8/site-packages/google/cloud/bigquery/job/query.py:1625\u001b[0m, in \u001b[0;36mQueryJob.result.<locals>.is_job_done\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1602\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m job_failed_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1603\u001b[0m     \u001b[38;5;66;03m# Only try to restart the query job if the job failed for\u001b[39;00m\n\u001b[1;32m   1604\u001b[0m     \u001b[38;5;66;03m# a retriable reason. For example, don't restart the query\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[38;5;66;03m# into an exception that can be processed by the\u001b[39;00m\n\u001b[1;32m   1623\u001b[0m     \u001b[38;5;66;03m# `job_retry` predicate.\u001b[39;00m\n\u001b[1;32m   1624\u001b[0m     restart_query_job \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1625\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m job_failed_exception\n\u001b[1;32m   1626\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1627\u001b[0m     \u001b[38;5;66;03m# Make sure that the _query_results are cached so we\u001b[39;00m\n\u001b[1;32m   1628\u001b[0m     \u001b[38;5;66;03m# can return a complete RowIterator.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1634\u001b[0m     \u001b[38;5;66;03m# making any extra API calls if the previous loop\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m     \u001b[38;5;66;03m# iteration fetched the finished job.\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reload_query_results(\n\u001b[1;32m   1637\u001b[0m         retry\u001b[38;5;241m=\u001b[39mretry, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mreload_query_results_kwargs\n\u001b[1;32m   1638\u001b[0m     )\n",
      "\u001b[0;31mBadRequest\u001b[0m: 400 Syntax error: Expected end of input but got identifier \"ASCLIMIT\" at [1:173]; reason: invalidQuery, location: query, message: Syntax error: Expected end of input but got identifier \"ASCLIMIT\" at [1:173]\n\nLocation: US\nJob ID: 32254874-aff3-4278-9ca6-7472a14915ef\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import bigquery\n",
    "\n",
    "client = bigquery.Client(project='cse3000')\n",
    "lol = ['0x1f1e784a61a8ca0a90250bcd2170696655b28a21']\n",
    "lil = ['0x1266f8b9e4dffc9e2f719bf51713f7e714516861']\n",
    "# Perform a query.\n",
    "QUERY = (\n",
    "    # 'SELECT to_address, from_address FROM `bigquery-public-data.crypto_ethereum.transactions` '\n",
    "    # f'WHERE to_address = {lol[0]}'\n",
    "    # f'AND from_address = {lil[0]}'\n",
    "    #f'WHERE to_address IN UNNEST({lol})'\n",
    "    #f'AND from_address IN UNNEST({lil})'\n",
    "    'SELECT * FROM `bigquery-public-data.crypto_ethereum.transactions`'\n",
    "    'WHERE block_timestamp BETWEEN TIMESTAMP(\"2015-08-07\") AND TIMESTAMP(\"2019-01-19\")'\n",
    "    'ORDER BY block_timestamp ASC LIMIT 10'\n",
    "\n",
    "    # 'LIMIT 100'\n",
    ")\n",
    "query_job = client.query(QUERY)  # API request\n",
    "rows = query_job.result()  # Waits for query to finish\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rel-mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
