{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "from torch_frame.data import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import negative_sampling\n",
    "from transformers import get_inverse_sqrt_schedule\n",
    "\n",
    "from src.datasets import IBMTransactionsAML\n",
    "from src.nn.gnn.model import GINe\n",
    "from src.utils import lp_loss\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 1024\n",
    "lr = 5e-4\n",
    "eps = 1e-8\n",
    "epochs = 20\n",
    "\n",
    "compile = True\n",
    "data_split = [0.6, 0.2, 0.2]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args = {\n",
    "    'testing': True,\n",
    "    'batch_size': batch_size,\n",
    "    'seed': seed,\n",
    "    'device': device,\n",
    "    'lr': lr,\n",
    "    'eps': eps,\n",
    "    'epochs': epochs,\n",
    "    'compile': compile,\n",
    "    'data_split': data_split\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maakyildiz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    mode=\"disabled\" if args['testing'] else \"online\",\n",
    "    project=f\"rel-mm\", \n",
    "    name=\"model=GINe,dataset=IBM-AML_Hi_Sm,objective=lp\", \n",
    "    config=args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "# When running on the CuDNN backend, two further options must be set\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# Set a fixed value for the hash seed\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dataset: IBMTransactionsAML()\n"
     ]
    }
   ],
   "source": [
    "dataset = IBMTransactionsAML(root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/dummy.csv')\n",
    "#dataset = IBMTransactionsAML(root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/HI-Small_Trans-cleaned.csv', pretrain=pretrain, split_type='temporal', splits=data_split)\n",
    "ic(dataset)\n",
    "dataset.materialize()\n",
    "dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=batch_size, shuffle=True)\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=batch_size, shuffle=True)\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_nodes: 298015\n",
      "ic| edge_index.shape: torch.Size([2, 499843])\n"
     ]
    }
   ],
   "source": [
    "# TODO: generalize the trainable columns\n",
    "source = train_tensor_frame.get_col_feat('From ID')\n",
    "destination = train_tensor_frame.get_col_feat('To ID')\n",
    "\n",
    "#create dummy node features\n",
    "num_nodes = np.unique(np.concatenate([source, destination])).shape[0]\n",
    "ic(num_nodes)\n",
    "node_feat = torch.ones(num_nodes)\n",
    "\n",
    "edge_index = torch.cat([source, destination], dim=1).t()\n",
    "ic(edge_index.shape)\n",
    "g = Data(node_feat, edge_index=edge_index, edge_attr=train_tensor_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| learnable_params: 125177\n"
     ]
    }
   ],
   "source": [
    "model = GINe(num_features=1, num_gnn_layers=3, edge_dim=train_dataset.tensor_frame.num_cols-3)\n",
    "model = torch.compile(model, dynamic=True) if compile else model\n",
    "model.to(args['device'])\n",
    "learnable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "ic(learnable_params)\n",
    "wandb.log({\"learnable_params\": learnable_params})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| batch: TensorFrame(\n",
      "             num_cols=10,\n",
      "             num_rows=1024,\n",
      "             categorical (7): ['From Bank', 'From ID',"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 'Payment Currency', 'Payment Format', 'Receiving Currency', 'To Bank', 'To ID'],\n",
      "             timestamp (1): ['Timestamp'],\n",
      "             numerical (2): ['Amount Paid', 'Amount Received'],\n",
      "             has_target=True,\n",
      "             device='cpu',\n",
      "           )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TensorFrame(\n",
       "  num_cols=10,\n",
       "  num_rows=1024,\n",
       "  categorical (7): ['From Bank', 'From ID', 'Payment Currency', 'Payment Format', 'Receiving Currency', 'To Bank', 'To ID'],\n",
       "  timestamp (1): ['Timestamp'],\n",
       "  numerical (2): ['Amount Paid', 'Amount Received'],\n",
       "  has_target=True,\n",
       "  device='cpu',\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_loader))\n",
    "ic(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| edge_index: tensor([[1029, 1641, 1738,  ...,  722, 1722,  285],\n",
      "                        [1035, 1704,  706,  ...,  204, 1688,  495]], device='cuda:0')\n",
      "    edge_attr: tensor([[5.3000e+01, 5.0000e+01, 0.0000e+00,  ..., 0.0000e+00, 1.3525e-10,\n",
      "                        1.3525e-10],\n",
      "                       [4.9100e+02, 4.8900e+02, 0.0000e+00,  ..., 0.0000e+00, 2.5417e-07,\n",
      "                        2.5417e-07],\n",
      "                       [8.2400e+02, 7.1400e+02, 4.0000e+00,  ..., 0.0000e+00, 1.5371e-06,\n",
      "                        1.5371e-06],\n",
      "                       ...,\n",
      "                       [1.0000e+00, 0.0000e+00, 1.4000e+01,  ..., 0.0000e+00, 8.4651e-07,\n",
      "                        8.4651e-07],\n",
      "                       [4.5900e+02, 4.3600e+02, 4.0000e+00,  ..., 0.0000e+00, 5.9275e-11,\n",
      "                        5.9275e-11],\n",
      "                       [2.4800e+02, 7.0000e+02, 4.0000e+00,  ..., 1.0000e+00, 8.8068e-08,\n",
      "                        8.8068e-08]], device='cuda:0')\n",
      "    node_feats: tensor([[1.],\n",
      "                        [1.],\n",
      "                        [1.],\n",
      "                        ...,\n",
      "                        [1.],\n",
      "                        [1.],\n",
      "                        [1.]], device='cuda:0')\n",
      "    neg_edge_index: tensor([[1150,  178, 1016,  ...,  356,  882, 1080],\n",
      "                            [ 449,  235,  489,  ...,  567,  170,  120]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[1029, 1641, 1738,  ...,  722, 1722,  285],\n",
       "         [1035, 1704,  706,  ...,  204, 1688,  495]], device='cuda:0'),\n",
       " tensor([[5.3000e+01, 5.0000e+01, 0.0000e+00,  ..., 0.0000e+00, 1.3525e-10,\n",
       "          1.3525e-10],\n",
       "         [4.9100e+02, 4.8900e+02, 0.0000e+00,  ..., 0.0000e+00, 2.5417e-07,\n",
       "          2.5417e-07],\n",
       "         [8.2400e+02, 7.1400e+02, 4.0000e+00,  ..., 0.0000e+00, 1.5371e-06,\n",
       "          1.5371e-06],\n",
       "         ...,\n",
       "         [1.0000e+00, 0.0000e+00, 1.4000e+01,  ..., 0.0000e+00, 8.4651e-07,\n",
       "          8.4651e-07],\n",
       "         [4.5900e+02, 4.3600e+02, 4.0000e+00,  ..., 0.0000e+00, 5.9275e-11,\n",
       "          5.9275e-11],\n",
       "         [2.4800e+02, 7.0000e+02, 4.0000e+00,  ..., 1.0000e+00, 8.8068e-08,\n",
       "          8.8068e-08]], device='cuda:0'),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         ...,\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]], device='cuda:0'),\n",
       " tensor([[1150,  178, 1016,  ...,  356,  882, 1080],\n",
       "         [ 449,  235,  489,  ...,  567,  170,  120]], device='cuda:0'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_gnn_inputs(batch):\n",
    "    source = batch.get_col_feat('From ID')\n",
    "    destination = batch.get_col_feat('To ID')\n",
    "    #ic(source, destination)\n",
    "    feat_cols = train_dataset.feat_cols\n",
    "\n",
    "    # TODO: generalize the trainable columns\n",
    "    feat_cols.remove('Timestamp')\n",
    "    feat_cols.remove('From ID')\n",
    "    feat_cols.remove('To ID')\n",
    "\n",
    "    # TODO: fix, a very crude approach\n",
    "    feats = [batch.get_col_feat(col_name) for col_name in feat_cols]\n",
    "    edge_attr = torch.cat(feats, dim=1).to(device)\n",
    "    nodes = torch.unique(torch.cat([source, destination]))\n",
    "    num_nodes = nodes.shape[0]\n",
    "\n",
    "    n_id_map = {value.item(): index for index, value in enumerate(nodes)}\n",
    "    local_source = torch.tensor([n_id_map[node.item()] for node in source], dtype=torch.long)\n",
    "    local_destination = torch.tensor([n_id_map[node.item()] for node in destination], dtype=torch.long)\n",
    "    edge_index = torch.cat((local_source.unsqueeze(0), local_destination.unsqueeze(0))).to(device)\n",
    "    node_feats = torch.ones(num_nodes).view(-1,num_nodes).t().to(device)\n",
    "    neg_edge_index = negative_sampling(edge_index=edge_index, num_nodes=num_nodes, num_neg_samples=local_source.shape[0])\n",
    "    return edge_index, edge_attr, node_feats, neg_edge_index\n",
    "edge_index, edge_attr, node_feats, neg_edge_index = get_gnn_inputs(batch)\n",
    "ic(edge_index, edge_attr, node_feats, neg_edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr, eps=eps)\n",
    "scheduler = get_inverse_sqrt_schedule(optimizer, num_warmup_steps=0, timescale=1000)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "def train(epoc: int) -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoc}') as t:\n",
    "        for tf in t:\n",
    "            tf = tf.to(device)\n",
    "            edge_index, edge_attr, node_feats, neg_edge_index = get_gnn_inputs(tf)\n",
    "            pred = model(node_feats, edge_index, edge_attr)\n",
    "            neg_pred = model(node_feats, neg_edge_index, edge_attr)\n",
    "            #loss = calc_loss(pred, tf.y)\n",
    "            loss = lp_loss(pred, neg_pred)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_accum += float(loss) * len(tf.y)\n",
    "            total_count += len(tf.y)\n",
    "            t.set_postfix(loss=f'{loss_accum/total_count:.4f}')\n",
    "            del pred\n",
    "            del tf\n",
    "        wandb.log({\"train_loss\": loss_accum/total_count})\n",
    "    return loss_accum / total_count\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: DataLoader, dataset_name) -> float:\n",
    "    model.eval()\n",
    "    accum_acc = 0\n",
    "    loss_accum = 0\n",
    "    total_count = 0\n",
    "    with tqdm(loader, desc=f'Evaluating') as t:\n",
    "        for tf in t:\n",
    "            tf = tf.to(device)\n",
    "            edge_index, edge_attr, node_feats, neg_edge_index = get_gnn_inputs(tf)\n",
    "            pred = model(node_feats, edge_index, edge_attr)\n",
    "            neg_pred = model(node_feats, neg_edge_index, edge_attr)\n",
    "            loss = lp_loss(pred, neg_pred)\n",
    "            loss_accum += float(loss) * (2 * len(pred))\n",
    "            accum_acc += pred.argmax(dim=1).sum().item()\n",
    "            accum_acc += len(neg_pred) - neg_pred.argmax(dim=1).sum().item()\n",
    "            total_count += len(pred) + len(neg_pred)\n",
    "            t.set_postfix(accuracy=f'{accum_acc/total_count:.4f}')\n",
    "        wandb.log({f\"{dataset_name}_accuracy\": accum_acc/total_count})\n",
    "        del tf\n",
    "        del pred\n",
    "        accuracy = accum_acc / total_count\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 489/489 [00:14<00:00, 33.71it/s, loss=1.3584]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 489/489 [00:12<00:00, 38.27it/s, accuracy=0.5131]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.57it/s, accuracy=0.5164]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 226.16it/s, accuracy=0.4947]\n",
      "ic| train_loss: 1.3584031641287861\n",
      "    train_metric: 0.5130611011857723\n",
      "    val_metric: 0.5163934426229508\n",
      "    test_metric: 0.49473684210526314\n",
      "Epoch 2: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 489/489 [00:14<00:00, 34.59it/s, loss=0.7209]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 489/489 [00:12<00:00, 37.91it/s, accuracy=0.5960]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 261.85it/s, accuracy=0.5984]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 231.69it/s, accuracy=0.5947]\n",
      "ic| train_loss: 0.7208677615201909\n",
      "    train_metric: 0.5959571305389892\n",
      "    val_metric: 0.5983606557377049\n",
      "    test_metric: 0.5947368421052631\n",
      "Epoch 3: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 489/489 [00:13<00:00, 35.00it/s, loss=0.5405]\n",
      "Evaluating: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 489/489 [00:12<00:00, 38.82it/s, accuracy=0.5098]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 280.20it/s, accuracy=0.5000]\n",
      "Evaluating: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 250.15it/s, accuracy=0.5000]\n",
      "ic| train_loss: 0.5405446931705202\n",
      "    train_metric: 0.5097970762819526\n",
      "    val_metric: 0.5\n",
      "    test_metric: 0.5\n",
      "Epoch 4:  46%|██████████████████████████████████████████████████████████████████████████████████▉                                                                                                   | 223/489 [00:06<00:07, 34.87it/s, loss=0.4033]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m     train_metric \u001b[38;5;241m=\u001b[39m test(train_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m     val_metric \u001b[38;5;241m=\u001b[39m test(val_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 18\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoc)\u001b[0m\n\u001b[1;32m     16\u001b[0m tf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     17\u001b[0m edge_index, edge_attr, node_feats, neg_edge_index \u001b[38;5;241m=\u001b[39m get_gnn_inputs(tf)\n\u001b[0;32m---> 18\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m neg_pred \u001b[38;5;241m=\u001b[39m model(node_feats, neg_edge_index, edge_attr)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#loss = calc_loss(pred, tf.y)\u001b[39;00m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rel-mm/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rel-mm/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/proj/models-for-relational-multimodal-data/src/nn/gnn/model.py:57\u001b[0m, in \u001b[0;36mGINe.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     54\u001b[0m         edge_attr \u001b[38;5;241m=\u001b[39m edge_attr \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39memlps[i](torch\u001b[38;5;241m.\u001b[39mcat([x[src], x[dst], edge_attr], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m     56\u001b[0m x \u001b[38;5;241m=\u001b[39m x[edge_index\u001b[38;5;241m.\u001b[39mT]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_hidden)\u001b[38;5;241m.\u001b[39mrelu()\n\u001b[0;32m---> 57\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x, \u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_attr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     58\u001b[0m out \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(out)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    train_metric = test(train_loader, \"train\")\n",
    "    val_metric = test(val_loader, \"val\")\n",
    "    test_metric = test(test_loader, \"test\")\n",
    "    ic(\n",
    "        train_loss, \n",
    "        train_metric, \n",
    "        val_metric, \n",
    "        test_metric\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
