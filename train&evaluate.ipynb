{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_frame import stype\n",
    "from torch_frame.datasets import Yandex\n",
    "from torch_frame.data import DataLoader\n",
    "from torch_frame.nn import (\n",
    "    EmbeddingEncoder,\n",
    "    FTTransformer,\n",
    "    LinearBucketEncoder,\n",
    "    LinearEncoder,\n",
    "    LinearPeriodicEncoder,\n",
    "    ResNet\n",
    ")\n",
    "from icecream import ic\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 512\n",
    "numerical_encoder_type = 'linear'\n",
    "model_type = 'fttransformer'\n",
    "channels = 256\n",
    "num_layers = 4\n",
    "\n",
    "compile = True\n",
    "lr = 1e-3\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dataset: Yandex(name='adult')\n",
      "ic| dataset.feat_cols: ['C_feature_0',\n",
      "                        'C_feature_1',\n",
      "                        'C_feature_2',\n",
      "                        'C_feature_3',\n",
      "                        'C_feature_4',\n",
      "                        'C_feature_5',\n",
      "                        'C_feature_6',\n",
      "                        'C_feature_7',\n",
      "                        'N_feature_0',\n",
      "                        'N_feature_1',\n",
      "                        'N_feature_2',\n",
      "                        'N_feature_3',\n",
      "                        'N_feature_4',\n",
      "                        'N_feature_5']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_feature_0</th>\n",
       "      <th>C_feature_1</th>\n",
       "      <th>C_feature_2</th>\n",
       "      <th>C_feature_3</th>\n",
       "      <th>C_feature_4</th>\n",
       "      <th>C_feature_5</th>\n",
       "      <th>C_feature_6</th>\n",
       "      <th>C_feature_7</th>\n",
       "      <th>N_feature_0</th>\n",
       "      <th>N_feature_1</th>\n",
       "      <th>N_feature_2</th>\n",
       "      <th>N_feature_3</th>\n",
       "      <th>N_feature_4</th>\n",
       "      <th>N_feature_5</th>\n",
       "      <th>target_col</th>\n",
       "      <th>split_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>nan</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>19.0</td>\n",
       "      <td>140399.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>50.0</td>\n",
       "      <td>158284.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>62.0</td>\n",
       "      <td>183735.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>20.0</td>\n",
       "      <td>154781.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>25.0</td>\n",
       "      <td>356344.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_feature_0   C_feature_1         C_feature_2        C_feature_3  \\\n",
       "0         nan  Some-college       Never-married                nan   \n",
       "1     Private  Some-college  Married-civ-spouse  Machine-op-inspct   \n",
       "2     Private  Some-college  Married-civ-spouse    Exec-managerial   \n",
       "3     Private       HS-grad       Never-married       Adm-clerical   \n",
       "4     Private     Bachelors       Never-married       Adm-clerical   \n",
       "\n",
       "      C_feature_4 C_feature_5 C_feature_6    C_feature_7  N_feature_0  \\\n",
       "0  Other-relative       White      Female  United-States         19.0   \n",
       "1         Husband       White        Male  United-States         50.0   \n",
       "2         Husband       White        Male  United-States         62.0   \n",
       "3   Not-in-family       White      Female  United-States         20.0   \n",
       "4       Own-child       White      Female  United-States         25.0   \n",
       "\n",
       "   N_feature_1  N_feature_2  N_feature_3  N_feature_4  N_feature_5  \\\n",
       "0     140399.0         10.0          0.0          0.0         30.0   \n",
       "1     158284.0         10.0          0.0          0.0         40.0   \n",
       "2     183735.0         10.0          0.0          0.0         40.0   \n",
       "3     154781.0          9.0          0.0          0.0         40.0   \n",
       "4     356344.0         13.0          0.0          0.0         40.0   \n",
       "\n",
       "   target_col  split_col  \n",
       "0           0          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Yandex(root='/tmp/yandex', name='adult')\n",
    "ic(dataset)\n",
    "ic(dataset.feat_cols)\n",
    "dataset.materialize()\n",
    "is_classification = dataset.task_type.is_classification\n",
    "dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| laundering.shape: (5177, 11)\n",
      "ic| dataset: AML()\n",
      "ic| is_classification: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>From ID</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>To ID</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200</td>\n",
       "      <td>B_3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>B_1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B_3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>B_3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>B_12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>B_12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp From Bank    From ID To Bank      To ID  Amount Received  \\\n",
       "0       1200      B_10  8000EBD30    B_10  8000EBD30          3697.34   \n",
       "1       1200    B_3208  8000F4580     B_1  8000F5340             0.01   \n",
       "2          0    B_3209  8000F4670  B_3209  8000F4670         14675.57   \n",
       "3        120      B_12  8000F5030    B_12  8000F5030          2806.97   \n",
       "4        360      B_10  8000F5200    B_10  8000F5200         36682.97   \n",
       "\n",
       "  Receiving Currency  Amount Paid Payment Currency Payment Format  \\\n",
       "0          US Dollar      3697.34        US Dollar   Reinvestment   \n",
       "1          US Dollar         0.01        US Dollar         Cheque   \n",
       "2          US Dollar     14675.57        US Dollar   Reinvestment   \n",
       "3          US Dollar      2806.97        US Dollar   Reinvestment   \n",
       "4          US Dollar     36682.97        US Dollar   Reinvestment   \n",
       "\n",
       "  Is Laundering  split  \n",
       "0             0      0  \n",
       "1             0      0  \n",
       "2             0      0  \n",
       "3             0      0  \n",
       "4             0      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch_frame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "class AML(torch_frame.data.Dataset):\n",
    "        def __init__(self, root):\n",
    "            self.root = root\n",
    "            names = [\n",
    "                'Timestamp',\n",
    "                'From Bank',\n",
    "                'From ID',\n",
    "                'To Bank',\n",
    "                'To ID',\n",
    "                'Amount Received',\n",
    "                'Receiving Currency',\n",
    "                'Amount Paid',\n",
    "                'Payment Currency',\n",
    "                'Payment Format',\n",
    "                'Is Laundering',\n",
    "            ]\n",
    "            dtypes = {\n",
    "                'From Bank': 'category',\n",
    "                'From ID': 'category',\n",
    "                'To Bank': 'category',\n",
    "                'To ID': 'category',\n",
    "                'Amount Received': 'float64',\n",
    "                'Receiving Currency': 'category',\n",
    "                'Amount Paid': 'float64',\n",
    "                'Payment Currency': 'category',\n",
    "                'Payment Format': 'category',\n",
    "                'Is Laundering': 'category',\n",
    "            }\n",
    "            self.df = pd.read_csv(root, names=names, dtype=dtypes, header=0)\n",
    "            laundering = self.df[self.df['Is Laundering'] == '1']\n",
    "            ic(laundering.shape)\n",
    "            self.temporal_balanced_split()\n",
    "            \n",
    "            col_to_stype = {\n",
    "                'Is Laundering': torch_frame.categorical,\n",
    "                'From ID': torch_frame.categorical,\n",
    "                'To ID': torch_frame.categorical,\n",
    "                'From Bank': torch_frame.categorical,\n",
    "                'To Bank': torch_frame.categorical,\n",
    "                'Payment Currency': torch_frame.categorical,\n",
    "                'Receiving Currency': torch_frame.categorical,\n",
    "                'Payment Format': torch_frame.categorical,\n",
    "                'Timestamp': torch_frame.numerical,\n",
    "                'Amount Paid': torch_frame.numerical,\n",
    "                'Amount Received': torch_frame.numerical\n",
    "            }\n",
    "            super().__init__(self.df, col_to_stype, split_col='split', target_col='Is Laundering')\n",
    "        \n",
    "        def random_split(self):\n",
    "            self.df['split'] = torch_frame.utils.generate_random_split(self.df.shape[0], seed)\n",
    "\n",
    "        def temporal_split(self):\n",
    "            self.df = self.df.sort_values(by='Timestamp')\n",
    "            train_size = int(self.df.shape[0] * 0.3)\n",
    "            validation_size = int(self.df.shape[0] * 0.1)\n",
    "            test_size = self.df.shape[0] - train_size - validation_size\n",
    "\n",
    "            #add split column, use 0 for train, 1 for validation, 2 for test\n",
    "            self.df['split'] = [0] * train_size + [1] * validation_size + [2] * test_size \n",
    "\n",
    "        def temporal_balanced_split(self):\n",
    "            assert 'Timestamp' in self.df.columns, \\\n",
    "            '\"transaction\" split is only available for datasets with a \"Timestamp\" column'\n",
    "            self.df['Timestamp'] = self.df['Timestamp'] - self.df['Timestamp'].min()\n",
    "\n",
    "            timestamps = torch.Tensor(self.df['Timestamp'].to_numpy())\n",
    "            n_days = int(timestamps.max() / (3600 * 24) + 1)\n",
    "\n",
    "            daily_inds, daily_trans = [], [] #irs = illicit ratios, inds = indices, trans = transactions\n",
    "            for day in range(n_days):\n",
    "                l = day * 24 * 3600\n",
    "                r = (day + 1) * 24 * 3600\n",
    "                day_inds = torch.where((timestamps >= l) & (timestamps < r))[0]\n",
    "                daily_inds.append(day_inds)\n",
    "                daily_trans.append(day_inds.shape[0])\n",
    "            \n",
    "            split_per = [0.6, 0.2, 0.2]\n",
    "            daily_totals = np.array(daily_trans)\n",
    "            d_ts = daily_totals\n",
    "            I = list(range(len(d_ts)))\n",
    "            split_scores = dict()\n",
    "            for i,j in itertools.combinations(I, 2):\n",
    "                if j >= i:\n",
    "                    split_totals = [d_ts[:i].sum(), d_ts[i:j].sum(), d_ts[j:].sum()]\n",
    "                    split_totals_sum = np.sum(split_totals)\n",
    "                    split_props = [v/split_totals_sum for v in split_totals]\n",
    "                    split_error = [abs(v-t)/t for v,t in zip(split_props, split_per)]\n",
    "                    score = max(split_error) #- (split_totals_sum/total) + 1\n",
    "                    split_scores[(i,j)] = score\n",
    "                else:\n",
    "                    continue\n",
    "\n",
    "            i,j = min(split_scores, key=split_scores.get)\n",
    "            # add split column, use 0 for train, 1 for validation, 2 for test\n",
    "            self.df['split'] = [0] * daily_totals[:i].sum() + [1] * daily_totals[i:j].sum() + [2] * daily_totals[j:].sum()\n",
    "\n",
    "dataset = AML(root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/HI-Small_Trans-cleaned.csv')\n",
    "ic(dataset)\n",
    "dataset.materialize()\n",
    "is_classification = dataset.task_type.is_classification\n",
    "ic(is_classification)\n",
    "dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trrain_dataset, val_dataset, test_dataset = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(train_loader): 6346\n",
      "    len(val_loader): 1886\n",
      "    len(test_loader): 1688\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6346, 1886, 1688)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor_frame = trrain_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=batch_size, shuffle=False)\n",
    "ic(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif numerical_encoder_type == 'linear_bucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif numerical_encoder_type == 'periodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(f'Unknown numerical encoder type: {numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    output_channels = dataset.num_classes\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'fttransformer':\n",
    "    model = FTTransformer(\n",
    "        channels=channels,\n",
    "        out_channels=output_channels,\n",
    "        num_layers=num_layers,\n",
    "        col_stats=dataset.col_stats,\n",
    "        col_names_dict=train_tensor_frame.col_names_dict,\n",
    "        stype_encoder_dict=stype_encoder_dict\n",
    "    ).to(device)\n",
    "elif model_type == 'resnet':\n",
    "    model = ResNet(\n",
    "        channels=channels,\n",
    "        out_channels=output_channels,\n",
    "        col_stats=dataset.col_stats,\n",
    "        col_names_dict=train_tensor_frame.col_names_dict,\n",
    "        stype_encoder_dict=stype_encoder_dict\n",
    "    ).to(device)\n",
    "else:\n",
    "    raise ValueError(f'Unknown model type: {model_type}')\n",
    "\n",
    "model = torch.compile(model, dynamic=True) if compile else model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "def train(epoc: int) -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoc}') as t:\n",
    "        for tf in t:\n",
    "            tf = tf.to(device)\n",
    "            pred = model(tf)\n",
    "            if is_classification:\n",
    "                loss = F.cross_entropy(pred, tf.y)\n",
    "            else:\n",
    "                loss = F.mse_loss(pred.view(-1), tf.y.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            loss_accum += float(loss) * len(tf.y)\n",
    "            total_count += len(tf.y)\n",
    "            optimizer.step()\n",
    "            t.set_postfix(loss=f'{loss_accum/total_count:.4f}')\n",
    "    return loss_accum / total_count\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accum = total_count = 0\n",
    "    confusion_matrix = [[0 for _ in range(dataset.num_classes)] for _ in range(dataset.num_classes)]\n",
    "    with tqdm(loader, desc=f'Evaluating') as t:\n",
    "        for tf in t:\n",
    "            tf = tf.to(device)\n",
    "            pred = model(tf)\n",
    "            total_count += len(tf.y)\n",
    "            if is_classification:\n",
    "                pred_class = pred.argmax(dim=-1)\n",
    "                #update confusion matrix\n",
    "                for r, p in zip(tf.y, pred_class):\n",
    "                    confusion_matrix[r][p] += 1\n",
    "                #display confusion matrix\n",
    "                #t.set_postfix(confusion_matrix=confusion_matrix)\n",
    "                accum += float((tf.y == pred_class).sum())\n",
    "                t.set_postfix(accuracy=f'{accum/total_count:.4f}')\n",
    "            else:\n",
    "                accum += float(F.mse_loss(pred.view(-1), tf.y.view(-1), reduction='sum'))\n",
    "\n",
    "        if is_classification:\n",
    "            accuracy = accum / total_count\n",
    "            return [confusion_matrix, accuracy]\n",
    "        else:\n",
    "            rmse = (accum / total_count) **0.5\n",
    "            return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 6346/6346 [03:16<00:00, 32.24it/s, loss=0.0077]\n",
      "Evaluating: 100%|██████████| 6346/6346 [01:14<00:00, 85.35it/s, accuracy=0.9990]\n",
      "Evaluating: 100%|██████████| 1886/1886 [00:21<00:00, 86.00it/s, accuracy=0.9990]\n",
      "ic| val_metric: [[[964590, 0], [934, 0]], 0.9990326496285955]\n",
      "Evaluating: 100%|██████████| 1688/1688 [00:19<00:00, 85.89it/s, accuracy=0.9987]\n",
      "ic| test_metric: [[[862785, 0], [1115, 0]], 0.9987093413589536]\n",
      "ic| train_loss: 0.007718086628077842\n",
      "    train_metric: [[[3245793, 0], [3128, 0]], 0.9990372188181861]\n",
      "    val_metric: [[[964590, 0], [934, 0]], 0.9990326496285955]\n",
      "    test_metric: [[[862785, 0], [1115, 0]], 0.9987093413589536]\n",
      "Epoch 2: 100%|██████████| 6346/6346 [03:17<00:00, 32.20it/s, loss=0.0077]\n",
      "Evaluating:  10%|█         | 658/6346 [00:07<01:08, 83.35it/s, accuracy=0.9990]"
     ]
    }
   ],
   "source": [
    "if is_classification:\n",
    "    metric = 'Acc'\n",
    "    best_val_metric = (None, 0)\n",
    "    best_test_metric = (None, 0)\n",
    "else:\n",
    "    metric = 'RMSE'\n",
    "    best_val_metric = float('inf')\n",
    "    best_test_metric = float('inf')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    train_metric = test(train_loader)\n",
    "    val_metric = test(val_loader)\n",
    "    ic(val_metric)\n",
    "    test_metric = test(test_loader)\n",
    "    ic(test_metric)\n",
    "\n",
    "    if is_classification and val_metric[1] > best_val_metric[1]:\n",
    "        best_val_metric = val_metric\n",
    "        best_test_metric = test_metric\n",
    "    elif not is_classification and val_metric < best_val_metric:\n",
    "        best_val_metric = val_metric\n",
    "        best_test_metric = test_metric\n",
    "\n",
    "    ic(train_loss, train_metric, val_metric, test_metric)\n",
    "\n",
    "ic(best_val_metric, best_test_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rel-mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
