{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch_frame.data import DataLoader\n",
    "from torch_frame import stype\n",
    "from torch_frame.nn import (\n",
    "    EmbeddingEncoder,\n",
    "    LinearEncoder,\n",
    "    TimestampEncoder,\n",
    ")\n",
    "from torch_frame import TensorFrame\n",
    "\n",
    "from transformers import get_inverse_sqrt_schedule\n",
    "\n",
    "from src.datasets import IBMTransactionsAML\n",
    "from src.nn.models import FTTransformerGINeFused\n",
    "from src.utils.loss import lp_loss\n",
    "from src.utils.metric import mrr\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "from icecream import ic\n",
    "import sys\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 200\n",
    "lr = 5e-4\n",
    "eps = 1e-8\n",
    "epochs = 3\n",
    "\n",
    "compile = False\n",
    "data_split = [0.6, 0.2, 0.2]\n",
    "split_type = 'temporal'\n",
    "\n",
    "khop_neighbors = [100, 100]\n",
    "pos_sample_prob = 0.15\n",
    "num_neg_samples = 64\n",
    "channels = 128\n",
    "\n",
    "pretrain = 'mask+lp'\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "args = {\n",
    "    'testing': True,\n",
    "    'batch_size': batch_size,\n",
    "    'seed': seed,\n",
    "    'device': device,\n",
    "    'lr': lr,\n",
    "    'eps': eps,\n",
    "    'epochs': epochs,\n",
    "    'compile': compile,\n",
    "    'data_split': data_split,\n",
    "    'pos_sample_prob': pos_sample_prob,\n",
    "    'channels': channels,\n",
    "    'split_type': split_type,\n",
    "    'num_neg_samples': num_neg_samples,\n",
    "    'pretrain': pretrain,\n",
    "    'khop_neighbors': khop_neighbors,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "# When running on the CuDNN backend, two further options must be set\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# Set a fixed value for the hash seed\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    }
   ],
   "source": [
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    mode=\"disabled\" if args['testing'] else \"online\",\n",
    "    project=f\"rel-mm\", \n",
    "    name=f\"model=FTTransformerGINeFusedEdgeUpdates,dataset=IBM-AML_Hi_Sm,objective=lp+mask,khop_neighs=[100,100],channels={channels},epoch=3\",\n",
    "    config=args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| self.df['link'][0:5]: 0         [0.0, 0.0, 0.0]\n",
      "                          1    [1.0, 298058.0, 1.0]\n",
      "                          2         [2.0, 2.0, 2.0]\n",
      "                          3         [3.0, 3.0, 3.0]\n",
      "                          4         [4.0, 4.0, 4.0]\n",
      "                          Name: link, dtype: object\n",
      "ic| self.df['mask'][0:5]: 0        [US Dollar, Payment Currency]\n",
      "                          1             [Cheque, Payment Format]\n",
      "                          2    [0.4535784064468698, Amount Paid]\n",
      "                          3       [Reinvestment, Payment Format]\n",
      "                          4       [Reinvestment, Payment Format]\n",
      "                          Name: mask, dtype: object\n",
      "ic| self.df['target'][0:5]: 0        [US Dollar, Payment Currency, 0.0, 0.0, 0.0]\n",
      "                            1        [Cheque, Payment Format, 1.0, 298058.0, 1.0]\n",
      "                            2    [0.4535784064468698, Amount Paid, 2.0, 2.0, 2.0]\n",
      "                            3       [Reinvestment, Payment Format, 3.0, 3.0, 3.0]\n",
      "                            4       [Reinvestment, Payment Format, 4.0, 4.0, 4.0]\n",
      "                            Name: target, dtype: object\n",
      "ic| dataset: IBMTransactionsAML()\n",
      "ic| len(train_dataset): 499843\n",
      "    len(val_dataset): 61\n",
      "    len(test_dataset): 95\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(499843, 61, 95)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = IBMTransactionsAML(\n",
    "    #root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/HI-Small_Trans-c.csv', \n",
    "    root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/dummy-c.csv', \n",
    "    pretrain=pretrain, \n",
    "    split_type=split_type, \n",
    "    splits=data_split, \n",
    "    khop_neighbors=khop_neighbors\n",
    ")\n",
    "ic(dataset)\n",
    "dataset.materialize()\n",
    "dataset.df.head(5)\n",
    "train_dataset, val_dataset, test_dataset = dataset.split()\n",
    "ic(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    \n",
    "g = torch.Generator()\n",
    "g.manual_seed(seed)\n",
    "tensor_frame = dataset.tensor_frame\n",
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=batch_size, shuffle=True, worker_init_fn=seed_worker, generator=g)\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g)\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=batch_size, shuffle=False, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_numerical: 2, num_categorical: 5, num_columns"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ": 7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 5, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_numerical = len(dataset.tensor_frame.col_names_dict[stype.numerical])\n",
    "num_categorical = len(dataset.tensor_frame.col_names_dict[stype.categorical])\n",
    "num_columns = num_numerical + num_categorical\n",
    "ic(num_numerical, num_categorical, num_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_frame.nn.encoder.stypewise_encoder import StypeWiseFeatureEncoder\n",
    "from torch_frame import NAStrategy\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: LinearEncoder(),\n",
    "    stype.timestamp: TimestampEncoder(na_strategy=NAStrategy.OLDEST_TIMESTAMP),\n",
    "}\n",
    "encoder = StypeWiseFeatureEncoder(\n",
    "            out_channels=channels,\n",
    "            col_stats=dataset.col_stats,\n",
    "            col_names_dict=train_tensor_frame.col_names_dict,\n",
    "            stype_encoder_dict=stype_encoder_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_rows(col_names_dict, num_rows):\n",
    "    feat_dict = {}\n",
    "    for stype, col_names in col_names_dict.items():\n",
    "        if stype == stype.categorical:\n",
    "            feat_dict[stype] = torch.full((num_rows, len(col_names)), -1)\n",
    "        elif stype == stype.numerical:\n",
    "            feat_dict[stype] = torch.full((num_rows, len(col_names)), float('NaN'))\n",
    "        elif stype == stype.timestamp:\n",
    "            #feat_dict[stype] = torch.full((num_rows, len(col_names)), -1)\n",
    "            #hack to get the timestamp encoder to work\n",
    "            row_values = [[1970, 0, 0, 3, 0, 0, 0]]\n",
    "            feat_dict[stype] = torch.tensor([row_values] * num_rows)\n",
    "    return feat_dict\n",
    "\n",
    "def inputs(tf: TensorFrame, pos_sample_prob=0.15, train=True):   \n",
    "    edges = tf.y\n",
    "    batch_size = len(edges)\n",
    "    # ic(edges[:, 2:])\n",
    "    # ic(edges[:, :2])\n",
    "    khop_source, khop_destination, idx = dataset.sample_neighbors(edges[:, 2:], train)\n",
    "\n",
    "    edge_data = tensor_frame.__getitem__(idx)\n",
    "    #ic(edge_data.feat_dict[stype.timestamp][0:5])\n",
    "\n",
    "    edge_attr, col_names = encoder(edge_data)\n",
    "    edge_attr = edge_attr.view(-1, len(col_names) * channels)\n",
    "\n",
    "    nodes = torch.unique(torch.cat([khop_source, khop_destination]))\n",
    "    num_nodes = nodes.shape[0] + 1 # add interaction node\n",
    "    node_feats = torch.ones(num_nodes).view(-1,num_nodes).t()\n",
    "\n",
    "    n_id_map = {value.item(): index+1 for index, value in enumerate(nodes)}\n",
    "    local_khop_source = torch.tensor([n_id_map[node.item()] for node in khop_source], dtype=torch.long)\n",
    "    local_khop_destination = torch.tensor([n_id_map[node.item()] for node in khop_destination], dtype=torch.long)\n",
    "    edge_index = torch.cat((local_khop_source.unsqueeze(0), local_khop_destination.unsqueeze(0)))\n",
    "    # ic(edge_index.shape, edge_attr.shape)\n",
    "\n",
    "    # sample positive edges\n",
    "    positions = torch.arange(batch_size)\n",
    "    num_samples = int(len(positions) * pos_sample_prob)\n",
    "    if len(positions) > 0 and num_samples > 0:\n",
    "        drop_idxs = torch.multinomial(torch.full((len(positions),), 1.0), num_samples, replacement=False)\n",
    "    else:\n",
    "        drop_idxs = torch.tensor([]).long()\n",
    "    drop_edge_ind = positions[drop_idxs]\n",
    "\n",
    "    mask = torch.zeros((edge_index.shape[1],)).long() #[E, ]\n",
    "    mask = mask.index_fill_(dim=0, index=drop_edge_ind, value=1).bool() #[E, ]\n",
    "    \n",
    "    # add interaction node to the graph\n",
    "    unique_nodes_ids = torch.unique(edges[:, 2:].t()[0:2].flatten())\n",
    "    local_unique_nodes_ids = torch.tensor([n_id_map[node.item()] for node in unique_nodes_ids], dtype=torch.long)\n",
    "    # ic(unique_nodes_ids.shape)\n",
    "    int_edges = torch.stack([local_unique_nodes_ids, torch.tensor([0] * local_unique_nodes_ids.shape[0])], dim=0)\n",
    "    int_edge_attr = TensorFrame(create_empty_rows(tensor_frame.col_names_dict, local_unique_nodes_ids.shape[0]), tensor_frame.col_names_dict)\n",
    "    input_edge_index = torch.cat([int_edges, edge_index[:, ~mask]], dim=1)\n",
    "    input_edge_attr  = torch.cat([encoder(int_edge_attr)[0].view(-1, len(col_names) * channels), edge_attr[~mask]], dim=0)\n",
    "    # ic(input_edge_index.shape, input_edge_attr.shape)\n",
    "\n",
    "    pos_edge_index = edge_index[:, mask]\n",
    "    pos_edge_attr  = edge_attr[mask]\n",
    "\n",
    "    # generate/sample negative edges\n",
    "    neg_edges = []\n",
    "    neg_edge_attr = []\n",
    "    nodeset = set(range(edge_index.max()+1))\n",
    "    for i, edge in enumerate(pos_edge_index.t()):\n",
    "        src, dst = edge[0], edge[1]\n",
    "\n",
    "        # Chose negative examples in a smart way\n",
    "        unavail_mask = (edge_index == src).any(dim=0) | (edge_index == dst).any(dim=0)\n",
    "        unavail_nodes = torch.unique(edge_index[:, unavail_mask])\n",
    "        unavail_nodes = set(unavail_nodes.tolist())\n",
    "        avail_nodes = nodeset - unavail_nodes\n",
    "        avail_nodes = torch.tensor(list(avail_nodes))\n",
    "        # Finally, emmulate np.random.choice() to chose randomly amongst available nodes\n",
    "        indices = torch.randperm(len(avail_nodes))[:num_neg_samples]\n",
    "        neg_nodes = avail_nodes[indices]\n",
    "        \n",
    "        # Generate num_neg_samples/2 negative edges with the same source but different destinations\n",
    "        num_neg_samples_half = int(num_neg_samples/2)\n",
    "        neg_dsts = neg_nodes[:num_neg_samples_half]  # Selecting num_neg_samples/2 random destination nodes for the source\n",
    "        neg_edges_src = torch.stack([src.repeat(num_neg_samples_half), neg_dsts], dim=0)\n",
    "        \n",
    "        # Generate num_neg_samples/2 negative edges with the same destination but different sources\n",
    "        neg_srcs = neg_nodes[num_neg_samples_half:]  # Selecting num_neg_samples/2 random source nodes for the destination\n",
    "        neg_edges_dst = torch.stack([neg_srcs, dst.repeat(num_neg_samples_half)], dim=0)\n",
    "\n",
    "        # Add these negative edges to the list\n",
    "        neg_edges.append(neg_edges_src)\n",
    "        neg_edges.append(neg_edges_dst)\n",
    "        # Replicate the positive edge attribute for each of the negative edges generated from this edge\n",
    "        pos_attr = pos_edge_attr[i].unsqueeze(0)  # Get the attribute of the current positive edge\n",
    "        \n",
    "        replicated_attr = pos_attr.repeat(num_neg_samples, 1)  # Replicate it num_neg_samples times (for each negative edge)\n",
    "        neg_edge_attr.append(replicated_attr)\n",
    "    \n",
    "    input_edge_index = input_edge_index.to(device)\n",
    "    input_edge_attr = input_edge_attr.to(device)\n",
    "    pos_edge_index = pos_edge_index.to(device)\n",
    "    pos_edge_attr = pos_edge_attr.to(device)\n",
    "    node_feats = node_feats.to(device)\n",
    "    neg_edge_index = torch.cat(neg_edges, dim=1).to(device)\n",
    "    neg_edge_attr = torch.cat(neg_edge_attr, dim=0).to(device)\n",
    "    return node_feats, edge_index, edge_attr, input_edge_index, input_edge_attr, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr\n",
    "\n",
    "def lp_inputs(tf: TensorFrame, pos_sample_prob=0.15, train=True):\n",
    "    \n",
    "    edges = tf.y[:, 2:]\n",
    "    batch_size = len(edges)\n",
    "    khop_source, khop_destination, idx = dataset.sample_neighbors(edges, train)\n",
    "    #del edges\n",
    "\n",
    "    edge_data = tensor_frame.__getitem__(idx)\n",
    "    edge_attr, col_names = encoder(edge_data)\n",
    "    edge_attr = edge_attr.view(-1, len(col_names) * channels)\n",
    "\n",
    "    nodes = torch.unique(torch.cat([khop_source, khop_destination]))\n",
    "    num_nodes = nodes.shape[0]\n",
    "    node_feats = torch.ones(num_nodes).view(-1,num_nodes).t()\n",
    "\n",
    "    n_id_map = {value.item(): index for index, value in enumerate(nodes)}\n",
    "    local_khop_source = torch.tensor([n_id_map[node.item()] for node in khop_source], dtype=torch.long)\n",
    "    local_khop_destination = torch.tensor([n_id_map[node.item()] for node in khop_destination], dtype=torch.long)\n",
    "    edge_index = torch.cat((local_khop_source.unsqueeze(0), local_khop_destination.unsqueeze(0)))\n",
    "\n",
    "    # sample positive edges\n",
    "    positions = torch.arange(batch_size)\n",
    "    num_samples = int(len(positions) * pos_sample_prob)\n",
    "    if len(positions) > 0 and num_samples > 0:\n",
    "        drop_idxs = torch.multinomial(torch.full((len(positions),), 1.0), num_samples, replacement=False)\n",
    "    else:\n",
    "        drop_idxs = torch.tensor([]).long()\n",
    "    drop_edge_ind = positions[drop_idxs]\n",
    "\n",
    "    mask = torch.zeros((edge_index.shape[1],)).long() #[E, ]\n",
    "    mask = mask.index_fill_(dim=0, index=drop_edge_ind, value=1).bool() #[E, ]\n",
    "    input_edge_index = edge_index[:, ~mask]\n",
    "    input_edge_attr  = edge_attr[~mask]\n",
    "\n",
    "    pos_edge_index = edge_index[:, mask]\n",
    "    pos_edge_attr  = edge_attr[mask]\n",
    "\n",
    "    # generate/sample negative edges\n",
    "    neg_edges = []\n",
    "    neg_edge_attr = []\n",
    "    nodeset = set(range(edge_index.max()+1))\n",
    "    for i, edge in enumerate(pos_edge_index.t()):\n",
    "        src, dst = edge[0], edge[1]\n",
    "\n",
    "        # Chose negative examples in a smart way\n",
    "        unavail_mask = (edge_index == src).any(dim=0) | (edge_index == dst).any(dim=0)\n",
    "        unavail_nodes = torch.unique(edge_index[:, unavail_mask])\n",
    "        unavail_nodes = set(unavail_nodes.tolist())\n",
    "        avail_nodes = nodeset - unavail_nodes\n",
    "        avail_nodes = torch.tensor(list(avail_nodes))\n",
    "        # Finally, emmulate np.random.choice() to chose randomly amongst available nodes\n",
    "        indices = torch.randperm(len(avail_nodes))[:num_neg_samples]\n",
    "        neg_nodes = avail_nodes[indices]\n",
    "        \n",
    "        # Generate num_neg_samples/2 negative edges with the same source but different destinations\n",
    "        num_neg_samples_half = int(num_neg_samples/2)\n",
    "        neg_dsts = neg_nodes[:num_neg_samples_half]  # Selecting num_neg_samples/2 random destination nodes for the source\n",
    "        neg_edges_src = torch.stack([src.repeat(num_neg_samples_half), neg_dsts], dim=0)\n",
    "        \n",
    "        # Generate num_neg_samples/2 negative edges with the same destination but different sources\n",
    "        neg_srcs = neg_nodes[num_neg_samples_half:]  # Selecting num_neg_samples/2 random source nodes for the destination\n",
    "        neg_edges_dst = torch.stack([neg_srcs, dst.repeat(num_neg_samples_half)], dim=0)\n",
    "\n",
    "        # Add these negative edges to the list\n",
    "        neg_edges.append(neg_edges_src)\n",
    "        neg_edges.append(neg_edges_dst)\n",
    "        # Replicate the positive edge attribute for each of the negative edges generated from this edge\n",
    "        pos_attr = pos_edge_attr[i].unsqueeze(0)  # Get the attribute of the current positive edge\n",
    "        \n",
    "        replicated_attr = pos_attr.repeat(num_neg_samples, 1)  # Replicate it num_neg_samples times (for each negative edge)\n",
    "        neg_edge_attr.append(replicated_attr)\n",
    "    \n",
    "    input_edge_index = input_edge_index.to(device)\n",
    "    input_edge_attr = input_edge_attr.to(device)\n",
    "    pos_edge_index = pos_edge_index.to(device)\n",
    "    pos_edge_attr = pos_edge_attr.to(device)\n",
    "    node_feats = node_feats.to(device)\n",
    "    neg_edge_index = torch.cat(neg_edges, dim=1).to(device)\n",
    "    neg_edge_attr = torch.cat(neg_edge_attr, dim=0).to(device)\n",
    "    return node_feats, edge_index, edge_attr, input_edge_index, input_edge_attr, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr\n",
    "\n",
    "# example = next(iter(train_loader))\n",
    "# node_feats, edge_index, edge_attr, input_edge_index, input_edge_attr, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr = inputs(example)\n",
    "# ic(node_feats.shape, edge_index.shape, edge_attr.shape, input_edge_index.shape, input_edge_attr.shape, pos_edge_index.shape, pos_edge_attr.shape, neg_edge_index.shape, neg_edge_attr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(cat_pred, num_pred, y):\n",
    "    accum_n = accum_c = t_n = t_c = 0\n",
    "    for i, ans in enumerate(y):\n",
    "        # ans --> [val, idx]\n",
    "        if ans[1] > (num_numerical-1):\n",
    "            t_c += 1\n",
    "            a = torch.tensor(int(ans[0])).to(device)\n",
    "            accum_c += F.cross_entropy(cat_pred[int(ans[1])-num_numerical][i], a)\n",
    "            del a\n",
    "        else:\n",
    "            t_n += 1\n",
    "            accum_n += torch.square(num_pred[i][int(ans[1])] - ans[0]) #mse\n",
    "    return (accum_n / t_n) + torch.sqrt(accum_c / t_c), (accum_c, t_c), (accum_n, t_n)\n",
    "\n",
    "def train(epoc: int, model, optimizer) -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "    loss_accum = loss_lp_accum = loss_c_accum = loss_n_accum = total_count = t_c = t_n = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoc}') as t:\n",
    "        for tf in t:\n",
    "            # time input processing\n",
    "            # start_input = time.time()\n",
    "            node_feats, _, _, input_edge_index, input_edge_attr, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr = lp_inputs(tf)\n",
    "            tf = tf.to(device)\n",
    "            # print(f\"Input processing time: {time.time() - start_input:.4f}\")\n",
    "            # # time model forward\n",
    "            # start_input = time.time()\n",
    "            num_pred, cat_pred, pos_pred, neg_pred = model(tf, node_feats, input_edge_index, input_edge_attr, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr)\n",
    "\n",
    "            \n",
    "            # ic(pos_pred, neg_pred)\n",
    "            link_loss = lp_loss(pos_pred, neg_pred)\n",
    "            t_loss, loss_c, loss_n = calc_loss(cat_pred, num_pred, tf.y)\n",
    "            loss = link_loss + t_loss\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # print(f\"Model forward time: {time.time() - start_input:.4f}\")\n",
    "            # sys.exit()\n",
    "\n",
    "            loss_accum += float(loss) * len(pos_pred)\n",
    "            total_count += len(pos_pred)\n",
    "            t_c += loss_c[1]\n",
    "            t_n += loss_n[1]\n",
    "            loss_c_accum += loss_c[0]\n",
    "            loss_n_accum += loss_n[0]\n",
    "            loss_lp_accum += link_loss * len(pos_pred)\n",
    "            t.set_postfix(loss=f'{loss_accum/total_count:.4f}')\n",
    "            del pos_pred\n",
    "            del neg_pred\n",
    "            del num_pred\n",
    "            del cat_pred\n",
    "            del tf\n",
    "        wandb.log({\"train_loss\": loss_accum/total_count, \"train_loss_lp\": loss_lp_accum/total_count, \"train_loss_c\": loss_c_accum/t_c, \"train_loss_n\": loss_n_accum/t_n})\n",
    "    return {'loss': loss_accum / total_count}\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: DataLoader, model, dataset_name) -> float:\n",
    "    model.eval()\n",
    "    mrrs = []\n",
    "    hits1 = []\n",
    "    hits2 = []\n",
    "    hits5 = []\n",
    "    hits10 = []\n",
    "    loss_accum = 0\n",
    "    total_count = 0\n",
    "    accum_acc = accum_l2 = 0\n",
    "    loss_accum = loss_lp_accum = loss_c_accum = loss_n_accum = total_count = t_c = t_n = 0\n",
    "    t_n = t_c = 0\n",
    "    with tqdm(loader, desc=f'Evaluating') as t:\n",
    "        for tf in t:\n",
    "            node_feats, _, _, input_edge_index, input_edge_attr, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr = lp_inputs(tf, train=False)\n",
    "            tf = tf.to(device)\n",
    "            num_pred, cat_pred, pos_pred, neg_pred = model(tf, node_feats, input_edge_index, input_edge_attr, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr)\n",
    "            link_loss = lp_loss(pos_pred, neg_pred)\n",
    "            t_loss, loss_c, loss_n = calc_loss(cat_pred, num_pred, tf.y)\n",
    "            loss = link_loss + t_loss\n",
    "            \n",
    "            t_c += loss_c[1]\n",
    "            t_n += loss_n[1] \n",
    "            loss_c_accum += loss_c[0]\n",
    "            loss_n_accum += loss_n[0]\n",
    "            loss_lp_accum += link_loss * len(pos_pred)\n",
    "            loss_accum += float(loss) * len(pos_pred)\n",
    "            total_count += len(pos_pred)\n",
    "            mrr_score, hits = mrr(pos_pred, neg_pred, [1,2,5,10], num_neg_samples)\n",
    "            mrrs.append(mrr_score)\n",
    "            hits1.append(hits['hits@1'])\n",
    "            hits2.append(hits['hits@2'])\n",
    "            hits5.append(hits['hits@5'])\n",
    "            hits10.append(hits['hits@10'])\n",
    "            for i, ans in enumerate(tf.y):\n",
    "                # ans --> [val, idx]\n",
    "                if ans[1] > (num_numerical-1):\n",
    "                    accum_acc += (cat_pred[int(ans[1])-num_numerical][i].argmax() == int(ans[0]))\n",
    "                else:\n",
    "                    accum_l2 += torch.square(ans[0] - num_pred[i][int(ans[1])]) #rmse\n",
    "            t.set_postfix(\n",
    "                loss=f'{loss_accum/total_count:.4f}',\n",
    "                mrr=f'{np.mean(mrrs):.4f}',\n",
    "                hits1=f'{np.mean(hits1):.4f}',\n",
    "                hits2=f'{np.mean(hits2):.4f}',\n",
    "                hits5=f'{np.mean(hits5):.4f}',\n",
    "                hits10=f'{np.mean(hits10):.4f}',\n",
    "                accuracy=f'{accum_acc / t_c:.4f}',\n",
    "                rmse=f'{torch.sqrt(accum_l2 / t_n):.4f}', \n",
    "                loss_mcm=f'{(loss_c_accum/t_c) + (loss_n_accum/t_n):.4f}',\n",
    "                loss_c = f'{loss_c_accum/t_c:.4f}', \n",
    "                loss_n = f'{loss_n_accum/t_n:.4f}',\n",
    "                loss_lp = f'{loss_lp_accum/total_count:.4f}',\n",
    "            )\n",
    "        mrr_score = np.mean(mrrs)\n",
    "        hits1 = np.mean(hits1)\n",
    "        hits2 = np.mean(hits2)\n",
    "        hits5 = np.mean(hits5)\n",
    "        hits10 = np.mean(hits10)\n",
    "        accuracy = accum_acc / t_c\n",
    "        rmse = torch.sqrt(accum_l2 / t_n)\n",
    "        wandb.log({\n",
    "            f\"{dataset_name}_loss\": loss_accum/total_count,\n",
    "            f\"{dataset_name}_mrr\": mrr_score,\n",
    "            f\"{dataset_name}_hits@1\": hits1,\n",
    "            f\"{dataset_name}_hits@2\": hits2,\n",
    "            f\"{dataset_name}_hits@5\": hits5,\n",
    "            f\"{dataset_name}_hits@10\": hits10,\n",
    "            f\"{dataset_name}_accuracy\": accuracy,\n",
    "            f\"{dataset_name}_rmse\": rmse,\n",
    "            f\"{dataset_name}_loss_c\": loss_c_accum/t_c,\n",
    "            f\"{dataset_name}_loss_n\": loss_n_accum/t_n,\n",
    "            f\"{dataset_name}_loss_lp\": loss_lp_accum/total_count,\n",
    "        })\n",
    "        del tf\n",
    "        del pos_pred\n",
    "        del neg_pred\n",
    "        del num_pred\n",
    "        del cat_pred\n",
    "        return {\"mrr\": mrr_score, \"hits@1\": hits1, \"hits@2\": hits2, \"hits@5\": hits5, \"hits@10\": hits10, \"accuracy\": accuracy, \"rmse\": rmse}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| learnable_params: 9044322\n",
      "Epoch 1: 100%|██████████| 2500/2500 [09:43<00:00,  4.28it/s, loss=1.7484]\n",
      "Evaluating: 100%|██████████| 2500/2500 [01:13<00:00, 34.12it/s, accuracy=0.8614, hits1=0.4152, hits10=0.5314, hits2=0.4533, hits5=0.5074, loss=1.4430, loss_c=0.4417, loss_lp=0.7546, loss_mcm=0.4687, loss_n=0.0269, mrr=0.4771, rmse=0.1641]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 74.27it/s, accuracy=0.4839, hits1=0.1111, hits10=0.3333, hits2=0.1111, hits5=0.3333, loss=3.4160, loss_c=3.0988, loss_lp=1.6435, loss_mcm=3.1109, loss_n=0.0121, mrr=0.1934, rmse=0.1101]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 72.08it/s, accuracy=0.3889, hits1=0.0714, hits10=0.5714, hits2=0.1429, hits5=0.2857, loss=3.5804, loss_c=3.8591, loss_lp=1.6028, loss_mcm=3.8723, loss_n=0.0131, mrr=0.2024, rmse=0.1146]\n",
      "ic| train_loss: {'loss': 1.7483785457517975}\n",
      "    train_metric: {'accuracy': tensor(0.8614, device='cuda:0'),\n",
      "                   'hits@1': 0.4151866666666667,\n",
      "                   'hits@10': 0.5314,\n",
      "                   'hits@2': 0.4532533333333333,\n",
      "                   'hits@5': 0.5074,\n",
      "                   'mrr': 0.47710717547273523,\n",
      "                   'rmse': tensor(0.1641, device='cuda:0')}\n",
      "    val_metric: {'accuracy': tensor(0.4839, device='cuda:0'),\n",
      "                 'hits@1': 0.1111111111111111,\n",
      "                 'hits@10': 0.3333333333333333,\n",
      "                 'hits@2': 0.1111111111111111,\n",
      "                 'hits@5': 0.3333333333333333,\n",
      "                 'mrr': 0.1933954008954009,\n",
      "                 'rmse': tensor(0.1101, device='cuda:0')}\n",
      "    test_metric: {'accuracy': tensor(0.3889, device='cuda:0'),\n",
      "                  'hits@1': 0.07142857142857142,\n",
      "                  'hits@10': 0.5714285714285714,\n",
      "                  'hits@2': 0.14285714285714285,\n",
      "                  'hits@5': 0.2857142857142857,\n",
      "                  'mrr': 0.20235484124856945,\n",
      "                  'rmse': tensor(0.1146, device='cuda:0')}\n",
      "Epoch 2:  38%|███▊      | 949/2500 [03:35<05:52,  4.40it/s, loss=1.4776]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 37\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# train_metric = test(train_loader, model, \"train\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# val_metric = test(val_loader, model, \"val\")\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# test_metric = test(test_loader, model, \"test\")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m#         test_metric\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 37\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     train_metric \u001b[38;5;241m=\u001b[39m test(train_loader, model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m     val_metric \u001b[38;5;241m=\u001b[39m test(val_loader, model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[26], line 30\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoc, model, optimizer)\u001b[0m\n\u001b[1;32m     26\u001b[0m tf \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# print(f\"Input processing time: {time.time() - start_input:.4f}\")\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# # time model forward\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# start_input = time.time()\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m num_pred, cat_pred, pos_pred, neg_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_edge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_edge_attr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_edge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mneg_edge_attr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# ic(pos_pred, neg_pred)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m link_loss \u001b[38;5;241m=\u001b[39m lp_loss(pos_pred, neg_pred)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rel-mm2/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dev/cse3000/src/nn/models/fused.py:199\u001b[0m, in \u001b[0;36mFTTransformerGINeFused.forward\u001b[0;34m(self, tf, x, edge_index, edge_attr, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr)\u001b[0m\n\u001b[1;32m    197\u001b[0m neg_edge_attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_emb(neg_edge_attr)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpretrain:\n\u001b[0;32m--> 199\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(\u001b[43mx_tab\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m, x_gnn, pos_edge_index, pos_edge_attr, neg_edge_index, neg_edge_attr)\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rel-mm2/lib/python3.10/site-packages/torch/fx/traceback.py:41\u001b[0m, in \u001b[0;36mformat_stack\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [current_meta\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstack_trace\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;66;03m# fallback to traceback.format_stack()\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtraceback\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rel-mm2/lib/python3.10/traceback.py:39\u001b[0m, in \u001b[0;36mformat_list\u001b[0;34m(extracted_list)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mformat_list\u001b[39m(extracted_list):\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Format a list of tuples or FrameSummary objects for printing.\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    Given a list of tuples or FrameSummary objects as returned by\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124;03m    whose source text line is not None.\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mStackSummary\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextracted_list\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rel-mm2/lib/python3.10/traceback.py:440\u001b[0m, in \u001b[0;36mStackSummary.format\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    439\u001b[0m row \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m--> 440\u001b[0m row\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m  File \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m, line \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m, in \u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlineno\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m frame\u001b[38;5;241m.\u001b[39mline:\n\u001b[1;32m    443\u001b[0m     row\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(frame\u001b[38;5;241m.\u001b[39mline\u001b[38;5;241m.\u001b[39mstrip()))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "torch.autograd.set_detect_anomaly(False)\n",
    "model = FTTransformerGINeFused(\n",
    "    channels=channels,\n",
    "    out_channels=None,\n",
    "    col_stats=dataset.col_stats,\n",
    "    col_names_dict=train_tensor_frame.col_names_dict,\n",
    "    edge_dim=channels*train_dataset.tensor_frame.num_cols,\n",
    "    num_layers=3, \n",
    "    dropout=0.5,\n",
    "    pretrain=True\n",
    ")\n",
    "model = torch.compile(model, dynamic=True) if compile else model\n",
    "model.to(device)\n",
    "learnable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "ic(learnable_params)\n",
    "wandb.log({\"learnable_params\": learnable_params})\n",
    "\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr, eps=eps)\n",
    "scheduler = get_inverse_sqrt_schedule(optimizer, num_warmup_steps=0, timescale=1000)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "# train_metric = test(train_loader, model, \"train\")\n",
    "# val_metric = test(val_loader, model, \"val\")\n",
    "# test_metric = test(test_loader, model, \"test\")\n",
    "# ic(\n",
    "#         train_metric, \n",
    "#         val_metric, \n",
    "#         test_metric\n",
    "# )\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(epoch, model, optimizer)\n",
    "    train_metric = test(train_loader, model, \"train\")\n",
    "    val_metric = test(val_loader, model, \"val\")\n",
    "    test_metric = test(test_loader, model, \"test\")\n",
    "    ic(\n",
    "        train_loss, \n",
    "        train_metric, \n",
    "        val_metric, \n",
    "        test_metric\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
