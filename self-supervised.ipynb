{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_frame import stype\n",
    "from torch_frame.data import DataLoader\n",
    "from torch_frame.nn import (\n",
    "    EmbeddingEncoder,\n",
    "    LinearEncoder,\n",
    "    TimestampEncoder,\n",
    ")\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import get_inverse_sqrt_schedule\n",
    "\n",
    "import sys\n",
    "from icecream import ic\n",
    "import wandb\n",
    "\n",
    "torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 1024\n",
    "channels = 256\n",
    "num_layers = 4\n",
    "\n",
    "data_split = [0.6, 0.2, 0.2]\n",
    "split_type = \"temporal\"\n",
    "\n",
    "pretrain = 'mask'\n",
    "compile = True\n",
    "lr = 5e-4\n",
    "eps = 1e-8\n",
    "epochs = 15\n",
    "args = {\n",
    "    \"testing\": False,\n",
    "    \"seed\": seed,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"channels\": channels,\n",
    "    \"num_layers\": num_layers,\n",
    "    \"pretrain\": pretrain,\n",
    "    \"compile\": compile,\n",
    "    \"lr\": lr,\n",
    "    \"eps\": eps,\n",
    "    \"epochs\": epochs,\n",
    "    \"data_split\": data_split,\n",
    "    \"split_type\": split_type,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maakyildiz\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/proj/models-for-relational-multimodal-data/wandb/run-20240419_103216-v9mg4nr9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aakyildiz/rel-mm/runs/v9mg4nr9' target=\"_blank\">model=fttransformer,dataset=IBM-AML_Hi_Sm,objective=MCM,loss=weighted_loss</a></strong> to <a href='https://wandb.ai/aakyildiz/rel-mm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aakyildiz/rel-mm' target=\"_blank\">https://wandb.ai/aakyildiz/rel-mm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aakyildiz/rel-mm/runs/v9mg4nr9' target=\"_blank\">https://wandb.ai/aakyildiz/rel-mm/runs/v9mg4nr9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.login()\n",
    "run = wandb.init(\n",
    "    mode=\"disabled\" if args['testing'] else \"online\",\n",
    "    project=f\"rel-mm\", \n",
    "    name=\"model=fttransformer,dataset=IBM-AML_Hi_Sm,objective=MCM,loss=weighted_loss\", \n",
    "    config=args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dataset: IBMTransactionsAML()\n",
      "ic| list(self._col_names_dict[stype.numerical]) + list(self._col_names_dict[stype.categorical]): ['Amount Paid',\n",
      "                                                                                                  'Amount Received',\n",
      "                                                                                                  'From Bank',\n",
      "                                                                                                  'From ID',\n",
      "                                                                                                  'Payment Currency',\n",
      "                                                                                                  'Payment Format',\n",
      "                                                                                                  'Receiving Currency',\n",
      "                                                                                                  'To Bank',\n",
      "                                                                                                  'To ID']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>From ID</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>To ID</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "      <th>MASK</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.296848</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.2968476112178767, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200</td>\n",
       "      <td>B_3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>B_1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 6]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B_3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>B_3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.346651</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.346650841620288, 1]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>B_12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>B_12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>0.286896</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.286896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 4]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>0.379751</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.3797509348152993, 0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp From Bank    From ID To Bank      To ID  Amount Received  \\\n",
       "0       1200      B_10  8000EBD30    B_10  8000EBD30              NaN   \n",
       "1       1200    B_3208  8000F4580     B_1  8000F5340         0.000359   \n",
       "2          0    B_3209  8000F4670  B_3209  8000F4670              NaN   \n",
       "3        120      B_12  8000F5030    B_12  8000F5030         0.286896   \n",
       "4        360      B_10  8000F5200    B_10  8000F5200         0.379751   \n",
       "\n",
       "  Receiving Currency  Amount Paid Payment Currency Payment Format  \\\n",
       "0          US Dollar     0.296848        US Dollar   Reinvestment   \n",
       "1                NaN     0.000359        US Dollar         Cheque   \n",
       "2          US Dollar     0.346651        US Dollar   Reinvestment   \n",
       "3          US Dollar     0.286896              NaN   Reinvestment   \n",
       "4          US Dollar          NaN        US Dollar   Reinvestment   \n",
       "\n",
       "  Is Laundering                     MASK  split  \n",
       "0             0  [0.2968476112178767, 1]      0  \n",
       "1             0                   [0, 6]      0  \n",
       "2             0   [0.346650841620288, 1]      0  \n",
       "3             0                   [0, 4]      0  \n",
       "4             0  [0.3797509348152993, 0]      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.datasets import IBMTransactionsAML\n",
    "#dataset = IBMTransactionsAML(root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/dummy.csv', pretrain=pretrain)\n",
    "dataset = IBMTransactionsAML(root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/HI-Small_Trans-c.csv', pretrain=pretrain, split_type='temporal', splits=data_split)\n",
    "ic(dataset)\n",
    "dataset.materialize()\n",
    "num_numerical = len(dataset.tensor_frame.col_names_dict[stype.numerical])\n",
    "num_categorical = len(dataset.tensor_frame.col_names_dict[stype.categorical])\n",
    "dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_numerical: 2, num_categorical: 7, num_columns: 9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2, 7, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = num_numerical + num_categorical\n",
    "ic(\n",
    "    num_numerical,\n",
    "    num_categorical,\n",
    "    num_columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "wandb.log({\"device\": str(device)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(train_loader): 3173\n",
      "    len(val_loader): 943\n",
      "    len(test_loader): 844\n"
     ]
    }
   ],
   "source": [
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=batch_size, shuffle=False)\n",
    "ic(len(train_loader), len(val_loader), len(test_loader))\n",
    "wandb.log({\n",
    "    \"train_loader size\": len(train_loader), \n",
    "    \"val_loader size\": len(val_loader), \n",
    "    \"test_loader size\": len(test_loader)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| learnable_params: 496110191\n"
     ]
    }
   ],
   "source": [
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: LinearEncoder(),\n",
    "    stype.timestamp: TimestampEncoder(),\n",
    "}\n",
    "\n",
    "from src.nn.models.ft_transformer import FTTransformer \n",
    "model = FTTransformer(\n",
    "    channels=channels,\n",
    "    out_channels=None,\n",
    "    num_layers=num_layers,\n",
    "    col_stats=dataset.col_stats,\n",
    "    col_names_dict=train_tensor_frame.col_names_dict,\n",
    "    stype_encoder_dict=stype_encoder_dict,\n",
    "    pretrain = pretrain\n",
    ").to(device)\n",
    "\n",
    "model = torch.compile(model, dynamic=True) if compile else model\n",
    "learnable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "ic(learnable_params)\n",
    "wandb.log({\"learnable_params\": learnable_params})\n",
    "\n",
    "# Prepare optimizer and lr scheduler\n",
    "no_decay = ['bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.0},\n",
    "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr, eps=eps)\n",
    "scheduler = get_inverse_sqrt_schedule(optimizer, num_warmup_steps=0, timescale=1000)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "def calc_loss(pred, y):\n",
    "    accum_n = accum_c = t_n = t_c = 0\n",
    "    for i, ans in enumerate(y):\n",
    "        # ans --> [val, idx]\n",
    "        # pred --> feature_type_num X type_num X batch_size\n",
    "        if ans[1] > (num_numerical-1):\n",
    "            t_c += 1\n",
    "            a = torch.tensor(int(ans[0])).to(device)\n",
    "            accum_c += F.cross_entropy(pred[1][int(ans[1])-num_numerical][i], a)\n",
    "            del a\n",
    "        else:\n",
    "            t_n += 1\n",
    "            accum_n += torch.square(pred[0][i][int(ans[1])] - ans[0]) #mse\n",
    "    return (accum_n / t_n) + torch.sqrt(accum_c / t_c), (accum_c, t_c), (accum_n, t_n)\n",
    "\n",
    "def train(epoc: int) -> float:\n",
    "    model.train()\n",
    "    loss_accum = loss_c_accum = loss_n_accum = total_count = t_c = t_n = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoc}') as t:\n",
    "        for tf in t:\n",
    "            tf = tf.to(device)\n",
    "            pred = model(tf)\n",
    "            loss, loss_c, loss_n = calc_loss(pred, tf.y)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_accum += float(loss) * len(tf.y)\n",
    "            loss_c_accum += loss_c[0]\n",
    "            loss_n_accum += loss_n[0]\n",
    "            total_count += len(tf.y)\n",
    "            t_c += loss_c[1]\n",
    "            t_n += loss_n[1]\n",
    "            t.set_postfix(loss=f'{loss_accum/total_count:.4f}', loss_c = f'{loss_c_accum/t_c:.4f}', loss_n = f'{loss_n_accum/t_n:.4f}')\n",
    "            del pred\n",
    "            del tf\n",
    "        wandb.log({\"train_loss\": loss_accum/total_count, \"train_loss_c\": loss_c_accum/t_c, \"train_loss_n\": loss_n_accum/t_n})\n",
    "    return ((loss_c_accum/t_c) * (num_categorical/num_columns)) + ((loss_n_accum/t_n) * (num_numerical/num_columns))\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: DataLoader, dataset_name) -> float:\n",
    "    model.eval()\n",
    "    accum_acc = accum_l2 = 0\n",
    "    loss_c_accum = loss_n_accum = 0\n",
    "    t_n = t_c = 0\n",
    "    with tqdm(loader, desc=f'Evaluating') as t:\n",
    "        for tf in t:\n",
    "            tf = tf.to(device)\n",
    "            pred = model(tf)\n",
    "            _, loss_c, loss_n = calc_loss(pred, tf.y)\n",
    "            loss_c_accum += loss_c[0]\n",
    "            loss_n_accum += loss_n[0]\n",
    "            t_c += loss_c[1]\n",
    "            t_n += loss_n[1]\n",
    "            for i, ans in enumerate(tf.y):\n",
    "                # ans --> [val, idx]\n",
    "                # pred --> feature_type_num X type_num X batch_size\n",
    "                if ans[1] > (num_numerical-1):\n",
    "                    accum_acc += (pred[1][int(ans[1])-num_numerical][i].argmax() == int(ans[0]))\n",
    "                else:\n",
    "                    accum_l2 += torch.square(ans[0] - pred[0][i][int(ans[1])]) #rmse\n",
    "            \n",
    "            t.set_postfix(accuracy=f'{accum_acc/t_c:.4f}', rmse=f'{torch.sqrt(accum_l2/t_n):.4f}', loss=f'{(loss_c_accum/t_c) + (loss_n_accum/t_n):.4f}', loss_c = f'{loss_c_accum/t_c:.4f}', loss_n = f'{loss_n_accum/t_n:.4f}')\n",
    "        wandb.log({f\"{dataset_name}_accuracy\": accum_acc/t_c, f\"{dataset_name}_rmse\": torch.sqrt(accum_l2/t_n), f\"{dataset_name}_loss\": ((loss_c_accum/t_c) * (num_categorical/num_columns)) + ((loss_n_accum/t_n) * (num_numerical/num_columns)), f\"{dataset_name}_loss_c\": loss_c_accum/t_c, f\"{dataset_name}_loss_n\": loss_n_accum/t_n})\n",
    "        del tf\n",
    "        del pred\n",
    "        accuracy = accum_acc / t_c\n",
    "        rmse = torch.sqrt(accum_l2 / t_n)\n",
    "        return [rmse, accuracy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|                                                                                | 0/3173 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|█| 3173/3173 [04:16<00:00, 12.39it/s, accuracy=0.0403, loss=2.7663, loss_c=2.5849, loss_n=0.1814, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:25<00:00, 10.98it/s, accuracy=0.0401, loss=2.7538, loss_c=2.5791, loss_n=0.1748, rmse=0.41\n",
      "Evaluating: 100%|█| 844/844 [01:16<00:00, 10.98it/s, accuracy=0.0397, loss=2.7554, loss_c=2.5816, loss_n=0.1738, rmse=0.41\n",
      "Epoch 1: 100%|█████████████████████████████| 3173/3173 [11:22<00:00,  4.65it/s, loss=0.7505, loss_c=0.5498, loss_n=0.0142]\n",
      "Evaluating: 100%|█| 3173/3173 [05:40<00:00,  9.31it/s, accuracy=0.8106, loss=0.4770, loss_c=0.4655, loss_n=0.0115, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:15<00:00, 12.44it/s, accuracy=0.7959, loss=0.4967, loss_c=0.4877, loss_n=0.0090, rmse=0.09\n",
      "Evaluating: 100%|█| 844/844 [01:07<00:00, 12.47it/s, accuracy=0.7908, loss=0.5071, loss_c=0.4982, loss_n=0.0090, rmse=0.09\n",
      "ic| train_loss: tensor(0.4308, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1072, device='cuda:0'), tensor(0.8106, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0950, device='cuda:0'), tensor(0.7959, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0946, device='cuda:0'), tensor(0.7908, device='cuda:0')]\n",
      "Epoch 2: 100%|█████████████████████████████| 3173/3173 [08:12<00:00,  6.44it/s, loss=0.6828, loss_c=0.4512, loss_n=0.0115]\n",
      "Evaluating: 100%|█| 3173/3173 [04:19<00:00, 12.21it/s, accuracy=0.8314, loss=0.4270, loss_c=0.4154, loss_n=0.0116, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:17<00:00, 12.21it/s, accuracy=0.8058, loss=0.4735, loss_c=0.4644, loss_n=0.0091, rmse=0.09\n",
      "Evaluating: 100%|█| 844/844 [01:08<00:00, 12.35it/s, accuracy=0.8009, loss=0.4842, loss_c=0.4752, loss_n=0.0090, rmse=0.09\n",
      "ic| train_loss: tensor(0.3535, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1078, device='cuda:0'), tensor(0.8314, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0954, device='cuda:0'), tensor(0.8058, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0950, device='cuda:0'), tensor(0.8009, device='cuda:0')]\n",
      "Epoch 3: 100%|█████████████████████████████| 3173/3173 [08:29<00:00,  6.23it/s, loss=0.6585, loss_c=0.4192, loss_n=0.0114]\n",
      "Evaluating: 100%|█| 3173/3173 [04:22<00:00, 12.07it/s, accuracy=0.8371, loss=0.4068, loss_c=0.3951, loss_n=0.0117, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:17<00:00, 12.15it/s, accuracy=0.8095, loss=0.4604, loss_c=0.4511, loss_n=0.0093, rmse=0.09\n",
      "Evaluating: 100%|█| 844/844 [01:09<00:00, 12.16it/s, accuracy=0.8051, loss=0.4709, loss_c=0.4617, loss_n=0.0092, rmse=0.09\n",
      "ic| train_loss: tensor(0.3286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1083, device='cuda:0'), tensor(0.8371, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0966, device='cuda:0'), tensor(0.8095, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0960, device='cuda:0'), tensor(0.8051, device='cuda:0')]\n",
      "Epoch 4: 100%|█████████████████████████████| 3173/3173 [08:28<00:00,  6.23it/s, loss=0.6457, loss_c=0.4030, loss_n=0.0114]\n",
      "Evaluating: 100%|█| 3173/3173 [04:20<00:00, 12.18it/s, accuracy=0.8393, loss=0.3938, loss_c=0.3825, loss_n=0.0112, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:16<00:00, 12.37it/s, accuracy=0.8114, loss=0.4552, loss_c=0.4465, loss_n=0.0087, rmse=0.09\n",
      "Evaluating: 100%|█| 844/844 [01:09<00:00, 12.08it/s, accuracy=0.8076, loss=0.4654, loss_c=0.4568, loss_n=0.0086, rmse=0.09\n",
      "ic| train_loss: tensor(0.3160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1059, device='cuda:0'), tensor(0.8393, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0932, device='cuda:0'), tensor(0.8114, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0930, device='cuda:0'), tensor(0.8076, device='cuda:0')]\n",
      "Epoch 5: 100%|█████████████████████████████| 3173/3173 [08:33<00:00,  6.18it/s, loss=0.6358, loss_c=0.3906, loss_n=0.0113]\n",
      "Evaluating: 100%|█| 3173/3173 [04:23<00:00, 12.03it/s, accuracy=0.8428, loss=0.3789, loss_c=0.3678, loss_n=0.0111, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:19<00:00, 11.83it/s, accuracy=0.8106, loss=0.4535, loss_c=0.4448, loss_n=0.0087, rmse=0.09\n",
      "Evaluating: 100%|█| 844/844 [01:11<00:00, 11.79it/s, accuracy=0.8059, loss=0.4657, loss_c=0.4571, loss_n=0.0086, rmse=0.09\n",
      "ic| train_loss: tensor(0.3063, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1054, device='cuda:0'), tensor(0.8428, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0933, device='cuda:0'), tensor(0.8106, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0929, device='cuda:0'), tensor(0.8059, device='cuda:0')]\n",
      "Epoch 6: 100%|█████████████████████████████| 3173/3173 [08:34<00:00,  6.16it/s, loss=0.6236, loss_c=0.3756, loss_n=0.0112]\n",
      "Evaluating: 100%|█| 3173/3173 [04:29<00:00, 11.76it/s, accuracy=0.8481, loss=0.3594, loss_c=0.3482, loss_n=0.0112, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:17<00:00, 12.16it/s, accuracy=0.8113, loss=0.4530, loss_c=0.4441, loss_n=0.0089, rmse=0.09\n",
      "Evaluating: 100%|█| 844/844 [01:09<00:00, 12.12it/s, accuracy=0.8075, loss=0.4687, loss_c=0.4598, loss_n=0.0088, rmse=0.09\n",
      "ic| train_loss: tensor(0.2946, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1059, device='cuda:0'), tensor(0.8481, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0946, device='cuda:0'), tensor(0.8113, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0940, device='cuda:0'), tensor(0.8075, device='cuda:0')]\n",
      "Epoch 7: 100%|█████████████████████████████| 3173/3173 [08:36<00:00,  6.14it/s, loss=0.6075, loss_c=0.3563, loss_n=0.0110]\n",
      "Evaluating: 100%|█| 3173/3173 [04:32<00:00, 11.63it/s, accuracy=0.8602, loss=0.3354, loss_c=0.3246, loss_n=0.0109, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:19<00:00, 11.84it/s, accuracy=0.8102, loss=0.4463, loss_c=0.4377, loss_n=0.0086, rmse=0.09\n",
      "Evaluating: 100%|█| 844/844 [01:11<00:00, 11.79it/s, accuracy=0.8063, loss=0.4646, loss_c=0.4562, loss_n=0.0085, rmse=0.09\n",
      "ic| train_loss: tensor(0.2796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1043, device='cuda:0'), tensor(0.8602, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0925, device='cuda:0'), tensor(0.8102, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0921, device='cuda:0'), tensor(0.8063, device='cuda:0')]\n",
      "Epoch 8: 100%|█████████████████████████████| 3173/3173 [08:37<00:00,  6.13it/s, loss=0.5897, loss_c=0.3356, loss_n=0.0109]\n",
      "Evaluating: 100%|█| 3173/3173 [04:22<00:00, 12.09it/s, accuracy=0.8701, loss=0.3080, loss_c=0.2974, loss_n=0.0106, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:17<00:00, 12.11it/s, accuracy=0.8107, loss=0.4398, loss_c=0.4317, loss_n=0.0082, rmse=0.09\n",
      "Evaluating: 100%|█| 844/844 [01:10<00:00, 12.01it/s, accuracy=0.8068, loss=0.4593, loss_c=0.4511, loss_n=0.0081, rmse=0.09\n",
      "ic| train_loss: tensor(0.2635, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1028, device='cuda:0'), tensor(0.8701, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0903, device='cuda:0'), tensor(0.8107, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0902, device='cuda:0'), tensor(0.8068, device='cuda:0')]\n",
      "Epoch 9: 100%|█████████████████████████████| 3173/3173 [08:30<00:00,  6.21it/s, loss=0.5717, loss_c=0.3153, loss_n=0.0107]\n",
      "Evaluating: 100%|█| 3173/3173 [04:26<00:00, 11.91it/s, accuracy=0.8809, loss=0.2861, loss_c=0.2758, loss_n=0.0103, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:17<00:00, 12.11it/s, accuracy=0.8132, loss=0.4478, loss_c=0.4398, loss_n=0.0080, rmse=0.08\n",
      "Evaluating: 100%|█| 844/844 [01:09<00:00, 12.15it/s, accuracy=0.8095, loss=0.4756, loss_c=0.4676, loss_n=0.0080, rmse=0.08\n",
      "ic| train_loss: tensor(0.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.1013, device='cuda:0'), tensor(0.8809, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0895, device='cuda:0'), tensor(0.8132, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0896, device='cuda:0'), tensor(0.8095, device='cuda:0')]\n",
      "Epoch 10: 100%|████████████████████████████| 3173/3173 [08:26<00:00,  6.27it/s, loss=0.5546, loss_c=0.2967, loss_n=0.0104]\n",
      "Evaluating: 100%|█| 3173/3173 [04:28<00:00, 11.82it/s, accuracy=0.8896, loss=0.2674, loss_c=0.2575, loss_n=0.0100, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:17<00:00, 12.11it/s, accuracy=0.8125, loss=0.4539, loss_c=0.4460, loss_n=0.0080, rmse=0.08\n",
      "Evaluating: 100%|█| 844/844 [01:11<00:00, 11.76it/s, accuracy=0.8087, loss=0.4799, loss_c=0.4719, loss_n=0.0080, rmse=0.08\n",
      "ic| train_loss: tensor(0.2331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.0998, device='cuda:0'), tensor(0.8896, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0892, device='cuda:0'), tensor(0.8125, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0893, device='cuda:0'), tensor(0.8087, device='cuda:0')]\n",
      "Epoch 11: 100%|████████████████████████████| 3173/3173 [08:31<00:00,  6.21it/s, loss=0.5391, loss_c=0.2803, loss_n=0.0102]\n",
      "Evaluating: 100%|█| 3173/3173 [04:25<00:00, 11.95it/s, accuracy=0.8967, loss=0.2501, loss_c=0.2404, loss_n=0.0097, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:18<00:00, 12.07it/s, accuracy=0.8141, loss=0.4591, loss_c=0.4513, loss_n=0.0079, rmse=0.08\n",
      "Evaluating: 100%|█| 844/844 [01:09<00:00, 12.13it/s, accuracy=0.8104, loss=0.4852, loss_c=0.4773, loss_n=0.0079, rmse=0.08\n",
      "ic| train_loss: tensor(0.2203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.0984, device='cuda:0'), tensor(0.8967, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0887, device='cuda:0'), tensor(0.8141, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0889, device='cuda:0'), tensor(0.8104, device='cuda:0')]\n",
      "Epoch 12: 100%|████████████████████████████| 3173/3173 [08:31<00:00,  6.20it/s, loss=0.5255, loss_c=0.2664, loss_n=0.0099]\n",
      "Evaluating: 100%|█| 3173/3173 [04:30<00:00, 11.71it/s, accuracy=0.9021, loss=0.2376, loss_c=0.2283, loss_n=0.0092, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:19<00:00, 11.92it/s, accuracy=0.8163, loss=0.4541, loss_c=0.4465, loss_n=0.0076, rmse=0.08\n",
      "Evaluating: 100%|█| 844/844 [01:11<00:00, 11.80it/s, accuracy=0.8129, loss=0.4816, loss_c=0.4740, loss_n=0.0077, rmse=0.08\n",
      "ic| train_loss: tensor(0.2094, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.0961, device='cuda:0'), tensor(0.9021, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0872, device='cuda:0'), tensor(0.8163, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0876, device='cuda:0'), tensor(0.8129, device='cuda:0')]\n",
      "Epoch 13: 100%|████████████████████████████| 3173/3173 [08:29<00:00,  6.23it/s, loss=0.5131, loss_c=0.2542, loss_n=0.0095]\n",
      "Evaluating: 100%|█| 3173/3173 [04:22<00:00, 12.07it/s, accuracy=0.9067, loss=0.2268, loss_c=0.2178, loss_n=0.0091, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:17<00:00, 12.22it/s, accuracy=0.8166, loss=0.4799, loss_c=0.4723, loss_n=0.0076, rmse=0.08\n",
      "Evaluating: 100%|█| 844/844 [01:08<00:00, 12.25it/s, accuracy=0.8133, loss=0.5089, loss_c=0.5012, loss_n=0.0077, rmse=0.08\n",
      "ic| train_loss: tensor(0.1998, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.0951, device='cuda:0'), tensor(0.9067, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0871, device='cuda:0'), tensor(0.8166, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0877, device='cuda:0'), tensor(0.8133, device='cuda:0')]\n",
      "Epoch 14: 100%|████████████████████████████| 3173/3173 [08:33<00:00,  6.18it/s, loss=0.5025, loss_c=0.2439, loss_n=0.0092]\n",
      "Evaluating: 100%|█| 3173/3173 [05:08<00:00, 10.30it/s, accuracy=0.9097, loss=0.2187, loss_c=0.2101, loss_n=0.0086, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:34<00:00,  9.95it/s, accuracy=0.8177, loss=0.4770, loss_c=0.4695, loss_n=0.0075, rmse=0.08\n",
      "Evaluating: 100%|█| 844/844 [01:25<00:00,  9.83it/s, accuracy=0.8144, loss=0.5100, loss_c=0.5024, loss_n=0.0076, rmse=0.08\n",
      "ic| train_loss: tensor(0.1918, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.0927, device='cuda:0'), tensor(0.9097, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0863, device='cuda:0'), tensor(0.8177, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0870, device='cuda:0'), tensor(0.8144, device='cuda:0')]\n",
      "Epoch 15: 100%|████████████████████████████| 3173/3173 [09:59<00:00,  5.30it/s, loss=0.4928, loss_c=0.2347, loss_n=0.0089]\n",
      "Evaluating: 100%|█| 3173/3173 [04:39<00:00, 11.34it/s, accuracy=0.9107, loss=0.2092, loss_c=0.2009, loss_n=0.0083, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:24<00:00, 11.11it/s, accuracy=0.8174, loss=0.5054, loss_c=0.4981, loss_n=0.0073, rmse=0.08\n",
      "Evaluating: 100%|█| 844/844 [01:25<00:00,  9.92it/s, accuracy=0.8140, loss=0.5376, loss_c=0.5301, loss_n=0.0074, rmse=0.08\n",
      "ic| train_loss: tensor(0.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.0910, device='cuda:0'), tensor(0.9107, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0853, device='cuda:0'), tensor(0.8174, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0862, device='cuda:0'), tensor(0.8140, device='cuda:0')]\n",
      "Epoch 16: 100%|████████████████████████████| 3173/3173 [09:46<00:00,  5.41it/s, loss=0.4841, loss_c=0.2268, loss_n=0.0086]\n",
      "Evaluating: 100%|█| 3173/3173 [04:28<00:00, 11.83it/s, accuracy=0.9149, loss=0.1988, loss_c=0.1909, loss_n=0.0079, rmse=0.\n",
      "Evaluating: 100%|█| 943/943 [01:20<00:00, 11.74it/s, accuracy=0.8166, loss=0.5225, loss_c=0.5155, loss_n=0.0070, rmse=0.08\n",
      "Evaluating: 100%|█| 844/844 [01:09<00:00, 12.10it/s, accuracy=0.8131, loss=0.5571, loss_c=0.5499, loss_n=0.0072, rmse=0.08\n",
      "ic| train_loss: tensor(0.1783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "    train_metric: [tensor(0.0886, device='cuda:0'), tensor(0.9149, device='cuda:0')]\n",
      "    val_metric: [tensor(0.0836, device='cuda:0'), tensor(0.8166, device='cuda:0')]\n",
      "    test_metric: [tensor(0.0849, device='cuda:0'), tensor(0.8131, device='cuda:0')]\n",
      "Epoch 17: 100%|████████████████████████████| 3173/3173 [08:36<00:00,  6.15it/s, loss=0.4768, loss_c=0.2202, loss_n=0.0083]\n",
      "Evaluating:  85%|▊| 2695/3173 [04:09<00:44, 10.78it/s, accuracy=0.9171, loss=0.1932, loss_c=0.1857, loss_n=0.0075, rmse=0.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkProcess-29:\n",
      "Process ForkProcess-4:\n",
      "Process ForkProcess-19:\n",
      "Process ForkProcess-5:\n",
      "Process ForkProcess-16:\n",
      "Process ForkProcess-28:\n",
      "Process ForkProcess-15:\n",
      "Process ForkProcess-32:\n",
      "Process ForkProcess-25:\n",
      "Process ForkProcess-31:\n",
      "Process ForkProcess-6:\n",
      "Process ForkProcess-23:\n",
      "Process ForkProcess-27:\n",
      "Process ForkProcess-18:\n",
      "Process ForkProcess-7:\n",
      "Process ForkProcess-30:\n",
      "Process ForkProcess-21:\n",
      "Process ForkProcess-14:\n",
      "Process ForkProcess-11:\n",
      "Process ForkProcess-20:\n",
      "Process ForkProcess-26:\n",
      "Process ForkProcess-10:\n",
      "Process ForkProcess-9:\n",
      "Process ForkProcess-8:\n",
      "Process ForkProcess-2:\n",
      "Process ForkProcess-12:\n",
      "Process ForkProcess-24:\n",
      "Process ForkProcess-17:\n",
      "Process ForkProcess-1:\n",
      "Process ForkProcess-22:\n",
      "Process ForkProcess-3:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 103, in get\n",
      "    res = self._recv_bytes()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/connection.py\", line 414, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "Process ForkProcess-13:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "KeyboardInterrupt\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/concurrent/futures/process.py\", line 240, in _process_worker\n",
      "    call_item = call_queue.get(block=True)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/queues.py\", line 102, in get\n",
      "    with self._rlock:\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      5\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m train(epoch)\n\u001b[0;32m----> 6\u001b[0m     train_metric \u001b[38;5;241m=\u001b[39m \u001b[43mtest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     val_metric \u001b[38;5;241m=\u001b[39m test(val_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m     test_metric \u001b[38;5;241m=\u001b[39m test(test_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/rel-mm/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 92\u001b[0m, in \u001b[0;36mtest\u001b[0;34m(loader, dataset_name)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, ans \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tf\u001b[38;5;241m.\u001b[39my):\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# ans --> [val, idx]\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# pred --> feature_type_num X type_num X batch_size\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ans[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m (num_numerical\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m---> 92\u001b[0m         accum_acc \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (pred[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mans\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m-\u001b[39mnum_numerical][i]\u001b[38;5;241m.\u001b[39margmax() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mint\u001b[39m(ans[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m         accum_l2 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msquare(ans[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m pred[\u001b[38;5;241m0\u001b[39m][i][\u001b[38;5;28mint\u001b[39m(ans[\u001b[38;5;241m1\u001b[39m])]) \u001b[38;5;66;03m#rmse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_metric = test(train_loader, \"train\")\n",
    "val_metric = test(val_loader, \"val\")\n",
    "test_metric = test(test_loader, \"test\")\n",
    "ic( \n",
    "    train_metric, \n",
    "    val_metric, \n",
    "    test_metric\n",
    ")\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    train_metric = test(train_loader, \"train\")\n",
    "    val_metric = test(val_loader, \"val\")\n",
    "    test_metric = test(test_loader, \"test\")\n",
    "    ic(\n",
    "        train_loss, \n",
    "        train_metric, \n",
    "        val_metric, \n",
    "        test_metric\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of src.datasets.ibm_transactions_for_aml failed: Traceback (most recent call last):\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/site-packages/IPython/extensions/autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/opt/miniconda3/envs/rel-mm/lib/python3.10/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 619, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 883, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
      "  File \"/proj/models-for-relational-multimodal-data/src/datasets/ibm_transactions_for_aml.py\", line 10, in <module>\n",
      "    class IBMTransactionsAML(torch_frame.data.Dataset):\n",
      "AttributeError: module 'torch_frame' has no attribute 'data'\n",
      "]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9102085404cc4c1ba53eabfff01d5f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.421 MB of 0.421 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>learnable_params</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁████████████████</td></tr><tr><td>test_loader size</td><td>▁</td></tr><tr><td>test_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss_c</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_loss_n</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>test_rmse</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▇▇▇▇▇▇██████████</td></tr><tr><td>train_loader size</td><td>▁</td></tr><tr><td>train_loss</td><td>█▃▂▃▂▃▂▃▂▃▂▃▁▃▁▃▁▃▁▂▁▂▁▂▁▂▁▂▁▂▁▂▁▂</td></tr><tr><td>train_loss_c</td><td>█▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss_n</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_rmse</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁████████████████</td></tr><tr><td>val_loader size</td><td>▁</td></tr><tr><td>val_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_c</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss_n</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_rmse</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>device</td><td>cuda</td></tr><tr><td>learnable_params</td><td>496110191</td></tr><tr><td>test_accuracy</td><td>0.81308</td></tr><tr><td>test_loader size</td><td>844</td></tr><tr><td>test_loss</td><td>0.42932</td></tr><tr><td>test_loss_c</td><td>0.54992</td></tr><tr><td>test_loss_n</td><td>0.00722</td></tr><tr><td>test_rmse</td><td>0.08495</td></tr><tr><td>train_accuracy</td><td>0.91487</td></tr><tr><td>train_loader size</td><td>3173</td></tr><tr><td>train_loss</td><td>0.47681</td></tr><tr><td>train_loss_c</td><td>0.22016</td></tr><tr><td>train_loss_n</td><td>0.00828</td></tr><tr><td>train_rmse</td><td>0.08863</td></tr><tr><td>val_accuracy</td><td>0.81657</td></tr><tr><td>val_loader size</td><td>943</td></tr><tr><td>val_loss</td><td>0.40253</td></tr><tr><td>val_loss_c</td><td>0.51555</td></tr><tr><td>val_loss_n</td><td>0.00698</td></tr><tr><td>val_rmse</td><td>0.08356</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">model=fttransformer,dataset=IBM-AML_Hi_Sm,objective=MCM,loss=weighted_loss</strong> at: <a href='https://wandb.ai/aakyildiz/rel-mm/runs/v9mg4nr9' target=\"_blank\">https://wandb.ai/aakyildiz/rel-mm/runs/v9mg4nr9</a><br/> View project at: <a href='https://wandb.ai/aakyildiz/rel-mm' target=\"_blank\">https://wandb.ai/aakyildiz/rel-mm</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240419_103216-v9mg4nr9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
