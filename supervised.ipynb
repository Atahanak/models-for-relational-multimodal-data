{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_frame import stype\n",
    "from torch_frame.datasets import Yandex\n",
    "from torch_frame.data import DataLoader\n",
    "from torch_frame.nn import (\n",
    "    EmbeddingEncoder,\n",
    "    FTTransformer,\n",
    "    TimestampEncoder,\n",
    "    LinearBucketEncoder,\n",
    "    LinearEncoder,\n",
    "    LinearPeriodicEncoder,\n",
    "    ResNet\n",
    ")\n",
    "from icecream import ic\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "batch_size = 512\n",
    "numerical_encoder_type = 'linear'\n",
    "model_type = 'fttransformer'\n",
    "channels = 256\n",
    "num_layers = 4\n",
    "\n",
    "compile = True\n",
    "lr = 1e-3\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dataset: Yandex(name='adult')\n",
      "ic| dataset.feat_cols: ['C_feature_0',\n",
      "                        'C_feature_1',\n",
      "                        'C_feature_2',\n",
      "                        'C_feature_3',\n",
      "                        'C_feature_4',\n",
      "                        'C_feature_5',\n",
      "                        'C_feature_6',\n",
      "                        'C_feature_7',\n",
      "                        'N_feature_0',\n",
      "                        'N_feature_1',\n",
      "                        'N_feature_2',\n",
      "                        'N_feature_3',\n",
      "                        'N_feature_4',\n",
      "                        'N_feature_5']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C_feature_0</th>\n",
       "      <th>C_feature_1</th>\n",
       "      <th>C_feature_2</th>\n",
       "      <th>C_feature_3</th>\n",
       "      <th>C_feature_4</th>\n",
       "      <th>C_feature_5</th>\n",
       "      <th>C_feature_6</th>\n",
       "      <th>C_feature_7</th>\n",
       "      <th>N_feature_0</th>\n",
       "      <th>N_feature_1</th>\n",
       "      <th>N_feature_2</th>\n",
       "      <th>N_feature_3</th>\n",
       "      <th>N_feature_4</th>\n",
       "      <th>N_feature_5</th>\n",
       "      <th>target_col</th>\n",
       "      <th>split_col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nan</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>nan</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>19.0</td>\n",
       "      <td>140399.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>50.0</td>\n",
       "      <td>158284.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Private</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>United-States</td>\n",
       "      <td>62.0</td>\n",
       "      <td>183735.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>20.0</td>\n",
       "      <td>154781.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>United-States</td>\n",
       "      <td>25.0</td>\n",
       "      <td>356344.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  C_feature_0   C_feature_1         C_feature_2        C_feature_3  \\\n",
       "0         nan  Some-college       Never-married                nan   \n",
       "1     Private  Some-college  Married-civ-spouse  Machine-op-inspct   \n",
       "2     Private  Some-college  Married-civ-spouse    Exec-managerial   \n",
       "3     Private       HS-grad       Never-married       Adm-clerical   \n",
       "4     Private     Bachelors       Never-married       Adm-clerical   \n",
       "\n",
       "      C_feature_4 C_feature_5 C_feature_6    C_feature_7  N_feature_0  \\\n",
       "0  Other-relative       White      Female  United-States         19.0   \n",
       "1         Husband       White        Male  United-States         50.0   \n",
       "2         Husband       White        Male  United-States         62.0   \n",
       "3   Not-in-family       White      Female  United-States         20.0   \n",
       "4       Own-child       White      Female  United-States         25.0   \n",
       "\n",
       "   N_feature_1  N_feature_2  N_feature_3  N_feature_4  N_feature_5  \\\n",
       "0     140399.0         10.0          0.0          0.0         30.0   \n",
       "1     158284.0         10.0          0.0          0.0         40.0   \n",
       "2     183735.0         10.0          0.0          0.0         40.0   \n",
       "3     154781.0          9.0          0.0          0.0         40.0   \n",
       "4     356344.0         13.0          0.0          0.0         40.0   \n",
       "\n",
       "   target_col  split_col  \n",
       "0           0          0  \n",
       "1           0          0  \n",
       "2           0          0  \n",
       "3           0          0  \n",
       "4           0          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Yandex(root='/tmp/yandex', name='adult')\n",
    "ic(dataset)\n",
    "ic(dataset.feat_cols)\n",
    "dataset.materialize()\n",
    "is_classification = dataset.task_type.is_classification\n",
    "dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| dataset: IBMTransactionsAML()\n",
      "ic| is_classification: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>From ID</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>To ID</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1200</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1200</td>\n",
       "      <td>B_3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>B_1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>B_3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>B_3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>14675.57</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>120</td>\n",
       "      <td>B_12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>B_12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2806.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>360</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>B_10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>36682.97</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp From Bank    From ID To Bank      To ID  Amount Received  \\\n",
       "0       1200      B_10  8000EBD30    B_10  8000EBD30          3697.34   \n",
       "1       1200    B_3208  8000F4580     B_1  8000F5340             0.01   \n",
       "2          0    B_3209  8000F4670  B_3209  8000F4670         14675.57   \n",
       "3        120      B_12  8000F5030    B_12  8000F5030          2806.97   \n",
       "4        360      B_10  8000F5200    B_10  8000F5200         36682.97   \n",
       "\n",
       "  Receiving Currency  Amount Paid Payment Currency Payment Format  \\\n",
       "0          US Dollar      3697.34        US Dollar   Reinvestment   \n",
       "1          US Dollar         0.01        US Dollar         Cheque   \n",
       "2          US Dollar     14675.57        US Dollar   Reinvestment   \n",
       "3          US Dollar      2806.97        US Dollar   Reinvestment   \n",
       "4          US Dollar     36682.97        US Dollar   Reinvestment   \n",
       "\n",
       "  Is Laundering  split  \n",
       "0             0      0  \n",
       "1             0      0  \n",
       "2             0      0  \n",
       "3             0      0  \n",
       "4             0      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_frame.datasets import IBMTransactionsAML\n",
    "dataset = IBMTransactionsAML(root='/mnt/data/ibm-transactions-for-anti-money-laundering-aml/dummy.csv')\n",
    "ic(dataset)\n",
    "dataset.materialize()\n",
    "is_classification = dataset.task_type.is_classification\n",
    "ic(is_classification)\n",
    "dataset.df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, val_dataset, test_dataset = dataset.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(train_loader): 977, len(val_loader): 1, len(test_loader): 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(977, 1, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tensor_frame = train_dataset.tensor_frame\n",
    "val_tensor_frame = val_dataset.tensor_frame\n",
    "test_tensor_frame = test_dataset.tensor_frame\n",
    "train_loader = DataLoader(train_tensor_frame, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_tensor_frame, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_tensor_frame, batch_size=batch_size, shuffle=False)\n",
    "ic(len(train_loader), len(val_loader), len(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| next(iter(train_loader)).feat_dict: {<stype.numerical: 'numerical'>: tensor([[84261.8672, 84261.8672],\n",
      "                                                [  206.3000,   206.3000],\n",
      "                                                [  327.1900,   327.1900],\n",
      "                                                ...,\n",
      "                                                [31433.6992, 31433.6992],\n",
      "                                                [ 9969.0400,  9969.0400],\n",
      "                                                [21614.0293, 21614.0293]]),\n",
      "                                         <stype.categorical: 'categorical'>: tensor([[    36,  29950,      1,  ...,      1,     37, 102997],\n",
      "                                                [     0,      0,      0,  ...,      0,     72,  23533],\n",
      "                                                [   348,  31404,      1,  ...,      1,    350, 131441],\n",
      "                                                ...,\n",
      "                                                [   508,  34393,      0,  ...,      0,    509,  94963],\n",
      "                                                [    30,  51073,     13,  ...,     13,     24,  83580],\n",
      "                                                [   181,  13110,      3,  ...,      3,      5,  92513]]),\n",
      "                                         <stype.timestamp: 'timestamp'>: tensor([[[1970,    0,    0,  ...,    0,    0,    0]],\n",
      "                                        \n",
      "                                                [[1970,    0,    0,  ...,    0,    0,    0]],\n",
      "                                        \n",
      "                                                [[1970,    0,    0,  ...,    0,    0,    0]],\n",
      "                                        \n",
      "                                                ...,\n",
      "                                        \n",
      "                                                [[1970,    0,    0,  ...,    0,    0,    0]],\n",
      "                                        \n",
      "                                                [[1970,    0,    0,  ...,    0,    0,    0]],\n",
      "                                        \n",
      "                                                [[1970,    0,    0,  ...,    0,    0,    0]]])}\n",
      "ic| next(iter(train_loader)).y: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "                                        0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print an example batch\n",
    "ic(next(iter(train_loader)).feat_dict)\n",
    "ic(next(iter(train_loader)).y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if numerical_encoder_type == 'linear':\n",
    "    numerical_encoder = LinearEncoder()\n",
    "elif numerical_encoder_type == 'linear_bucket':\n",
    "    numerical_encoder = LinearBucketEncoder()\n",
    "elif numerical_encoder_type == 'periodic':\n",
    "    numerical_encoder = LinearPeriodicEncoder()\n",
    "else:\n",
    "    raise ValueError(f'Unknown numerical encoder type: {numerical_encoder_type}')\n",
    "\n",
    "stype_encoder_dict = {\n",
    "    stype.categorical: EmbeddingEncoder(),\n",
    "    stype.numerical: numerical_encoder,\n",
    "    stype.timestamp: TimestampEncoder(),\n",
    "}\n",
    "\n",
    "if is_classification:\n",
    "    output_channels = dataset.num_classes\n",
    "else:\n",
    "    output_channels = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'fttransformer':\n",
    "    model = FTTransformer(\n",
    "        channels=channels,\n",
    "        out_channels=output_channels,\n",
    "        num_layers=num_layers,\n",
    "        col_stats=dataset.col_stats,\n",
    "        col_names_dict=train_tensor_frame.col_names_dict,\n",
    "        stype_encoder_dict=stype_encoder_dict\n",
    "    ).to(device)\n",
    "elif model_type == 'resnet':\n",
    "    model = ResNet(\n",
    "        channels=channels,\n",
    "        out_channels=output_channels,\n",
    "        col_stats=dataset.col_stats,\n",
    "        col_names_dict=train_tensor_frame.col_names_dict,\n",
    "        stype_encoder_dict=stype_encoder_dict\n",
    "    ).to(device)\n",
    "else:\n",
    "    raise ValueError(f'Unknown model type: {model_type}')\n",
    "\n",
    "model = torch.compile(model, dynamic=True) if compile else model\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "\n",
    "def train(epoc: int) -> float:\n",
    "    model.train()\n",
    "    loss_accum = total_count = 0\n",
    "\n",
    "    with tqdm(train_loader, desc=f'Epoch {epoc}') as t:\n",
    "        for tf in t:\n",
    "            tf = tf.to(device)\n",
    "            pred = model(tf)\n",
    "            if is_classification:\n",
    "                loss = F.cross_entropy(pred, tf.y)\n",
    "            else:\n",
    "                loss = F.mse_loss(pred.view(-1), tf.y.view(-1))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            loss_accum += float(loss) * len(tf.y)\n",
    "            total_count += len(tf.y)\n",
    "            optimizer.step()\n",
    "            t.set_postfix(loss=f'{loss_accum/total_count:.4f}')\n",
    "    return loss_accum / total_count\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(loader: DataLoader) -> float:\n",
    "    model.eval()\n",
    "    accum = total_count = 0\n",
    "    confusion_matrix = [[0 for _ in range(dataset.num_classes)] for _ in range(dataset.num_classes)]\n",
    "    with tqdm(loader, desc=f'Evaluating') as t:\n",
    "        for tf in t:\n",
    "            tf = tf.to(device)\n",
    "            pred = model(tf)\n",
    "            total_count += len(tf.y)\n",
    "            if is_classification:\n",
    "                pred_class = pred.argmax(dim=-1)\n",
    "                #update confusion matrix\n",
    "                for r, p in zip(tf.y, pred_class):\n",
    "                    confusion_matrix[r][p] += 1\n",
    "                #display confusion matrix\n",
    "                #t.set_postfix(confusion_matrix=confusion_matrix)\n",
    "                accum += float((tf.y == pred_class).sum())\n",
    "                t.set_postfix(accuracy=f'{accum/total_count:.4f}')\n",
    "            else:\n",
    "                accum += float(F.mse_loss(pred.view(-1), tf.y.view(-1), reduction='sum'))\n",
    "\n",
    "        if is_classification:\n",
    "            accuracy = accum / total_count\n",
    "            return [confusion_matrix, accuracy]\n",
    "        else:\n",
    "            rmse = (accum / total_count) **0.5\n",
    "            return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/977 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rel-mm/lib/python3.10/site-packages/torch/_inductor/compile_fx.py:140: UserWarning: TensorFloat32 tensor cores for float32 matrix multiplication available but not enabled. Consider setting `torch.set_float32_matmul_precision('high')` for better performance.\n",
      "  warnings.warn(\n",
      "Epoch 1: 100%|██████████| 977/977 [00:34<00:00, 28.56it/s, loss=0.0040]\n",
      "Evaluating: 100%|██████████| 977/977 [00:13<00:00, 71.29it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 393.91it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 334.90it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.003999752386029505\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 2: 100%|██████████| 977/977 [00:21<00:00, 44.63it/s, loss=0.0027]\n",
      "Evaluating: 100%|██████████| 977/977 [00:11<00:00, 84.95it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 397.83it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 341.69it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.0027073161381999684\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 3: 100%|██████████| 977/977 [00:21<00:00, 44.53it/s, loss=0.0032]\n",
      "Evaluating: 100%|██████████| 977/977 [00:11<00:00, 82.91it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 425.30it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 350.69it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.0031941849734464134\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 4: 100%|██████████| 977/977 [00:21<00:00, 44.53it/s, loss=0.0035]\n",
      "Evaluating: 100%|██████████| 977/977 [00:11<00:00, 83.04it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 411.89it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 350.69it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.003473823114572587\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 5: 100%|██████████| 977/977 [00:21<00:00, 44.67it/s, loss=0.0035]\n",
      "Evaluating: 100%|██████████| 977/977 [00:11<00:00, 84.85it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 437.96it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 350.69it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.0034849185044099062\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 6: 100%|██████████| 977/977 [00:21<00:00, 44.64it/s, loss=0.0034]\n",
      "Evaluating: 100%|██████████| 977/977 [00:11<00:00, 83.41it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 418.76it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 343.99it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.0034287358590266792\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 7: 100%|██████████| 977/977 [00:22<00:00, 44.34it/s, loss=0.0035]\n",
      "Evaluating: 100%|██████████| 977/977 [00:11<00:00, 81.66it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 389.30it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 335.81it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.0034721312097862698\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 8: 100%|██████████| 977/977 [00:21<00:00, 44.68it/s, loss=0.0035]\n",
      "Evaluating: 100%|██████████| 977/977 [00:12<00:00, 80.09it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 414.33it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 339.15it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.0034778304727032935\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 9: 100%|██████████| 977/977 [00:21<00:00, 44.67it/s, loss=0.0035]\n",
      "Evaluating: 100%|██████████| 977/977 [00:11<00:00, 84.61it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 425.99it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 346.81it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.0034762081001748477\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "Epoch 10: 100%|██████████| 977/977 [00:21<00:00, 44.51it/s, loss=0.0035]\n",
      "Evaluating: 100%|██████████| 977/977 [00:11<00:00, 83.32it/s, accuracy=0.9996]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 419.98it/s, accuracy=1.0000]\n",
      "ic| val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 345.67it/s, accuracy=1.0000]\n",
      "ic| test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| train_loss: 0.003474065011053576\n",
      "    train_metric: [[[499650, 0], [193, 0]], 0.99961387875793]\n",
      "    val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    test_metric: [[[95, 0], [0, 0]], 1.0]\n",
      "ic| best_val_metric: [[[61, 0], [0, 0]], 1.0]\n",
      "    best_test_metric: [[[95, 0], [0, 0]], 1.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[[61, 0], [0, 0]], 1.0], [[[95, 0], [0, 0]], 1.0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if is_classification:\n",
    "    metric = 'Acc'\n",
    "    best_val_metric = (None, 0)\n",
    "    best_test_metric = (None, 0)\n",
    "else:\n",
    "    metric = 'RMSE'\n",
    "    best_val_metric = float('inf')\n",
    "    best_test_metric = float('inf')\n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    train_loss = train(epoch)\n",
    "    train_metric = test(train_loader)\n",
    "    val_metric = test(val_loader)\n",
    "    ic(val_metric)\n",
    "    test_metric = test(test_loader)\n",
    "    ic(test_metric)\n",
    "\n",
    "    if is_classification and val_metric[1] > best_val_metric[1]:\n",
    "        best_val_metric = val_metric\n",
    "        best_test_metric = test_metric\n",
    "    elif not is_classification and val_metric < best_val_metric:\n",
    "        best_val_metric = val_metric\n",
    "        best_test_metric = test_metric\n",
    "\n",
    "    ic(train_loss, train_metric, val_metric, test_metric)\n",
    "\n",
    "ic(best_val_metric, best_test_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rel-mm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
